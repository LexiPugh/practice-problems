# **Welcome to My Practice Problems Repository!**

<br>

**Table of Contents**

-   [Introduction](#introduction)
-   [List of Questions](#list-of-questions)
    - [December 2023](#december-2023)
    - [January 2024](#january-2024)
    - [February 2024](#february-2024)
    - [March 2024](#march-2024)
    - [April 2024](#april-2024)
    - [May 2024](#may-2024)
    - [June 2024](#june-2024)

<br>

## Introduction

Starting on December 1st 2023, I'm going to do one practice problem per day! My goal with this repository is to:
- Further my coding skills to land a data analyst position
- Build up my GitHub profile

I'll continue doing these practice problems at least until I land a job as a data analyst, and possibly even after that! The practice questions will come from a variety of sources, such as:
- [DataLemur](https://datalemur.com/) 
- [Analyst Builder](https://www.analystbuilder.com/) 
- [HackerRank](https://www.hackerrank.com/domains/sql)

Some of the practice problems will be in SQL and some will be in Python. Thank you for taking the time to view my practice problems repository :D

<br>

## List of Questions

### December 2023 

<details>

<summary>December 2023 Practice Problems</summary>

<br>

1. Day 1 - December 1st 2023: [Histogram of Tweets from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day1.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Subqueries, the DATE_PART function
2. Day 2 - December 2nd 2023: [Data Science Skills from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day2.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using the HAVING keyword to filter on aggregated data
3. Day 3 - December 3rd 2023: [Combine Two Tables from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day3.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the LEFT JOIN keyword to join the employee names on the employee locations, being sure to keep all employee names even if they don't exist in the location table. Used the ORDER BY keyword to order by first name alphabetically
4. Day 4 - December 4th 2023: [Page With No Likes from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day4.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: The IS NULL keyword, using a LEFT JOIN
5. Day 5 - December 5th 2023: [Big GDP from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day5.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the WHERE keyword to filter by GDP and used the ORDER BY keyword to order by the country name alphabetically
6. Day 6 - December 6th 2023: [Shopping Cart Conversions from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day6.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation to engineer a new feature, specifically the percentage of items that customers put in their cart that they actually bought. Used the ROUND() function to round to two decimal places and the ORDER BY keyword to order by customer id
7. Day 7 - December 7th 2023: [Most Orders from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day7.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used a subquery in the WHERE clause to filter to the customers with the MAX() number of orders
8. Day 8 - December 8th 2023: [Duplicate Emails from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day8.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the COUNT() function and the GROUP BY keyword to count the number of emails and group by email. I then used the HAVING keyword to filter on the aggregation and find instances where the email count was greater than 1, singling out users with duplicate emails. I used the ORDER BY keyword to order the output by email alphabetically
9. Day 9 - December 9th 2023: [Laptop vs. Mobile Viewership from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day9.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using a CASE statement and an aggregation function to engineer new features
10. Day 10 - December 10th 2023: [Unfinished Parts from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day10.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using the IS NULL keyword to filter to instances where a row value is missing
11. Day 11 - December 11th 2023: [Factorial Formula from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day11.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Utilizing a for loop for numeric calculations
12. Day 12 - December 12th 2023: [Movie Theater from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day12.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the WHERE and IN keywords together to filter on multiple values
13. Day 13 - December 13th 2023: [Heart Attack Risk from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day13.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the WHERE keyword, AND keyword, and inequalities to filter on multiple conditions that would put a patient at risk of a heart attack. Used the ORDER BY keyword to order by cholesterol descending since that's the most important indicator
14. Day 14 - December 14th 2023: [Wealthy Customers from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day14.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used COUNT DISTINCT to count the unique number of customers and used the WHERE keyword to filter to customers that spent at least 500 dollars in a single order
15. Day 15 - December 15th 2023: [Ice Cream Popularity from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day15.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used comparison operators and the WHERE keyword to compare two fields for the purpose of filtering. Used the ORDER BY keyword to order the output by ice cream flavor alphabetically
16. Day 16 - December 16th 2023: [Gamer Tags from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day16.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the LEFT function to select part of a string, the YEAR function to select part of a date, and the CONCAT function to combine them. Used the ORDER BY keyword to order by gamer tag
17. Day 17 - December 17th 2023: [Teams Power Users from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day17.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Aggregating with the COUNT() function, using the GROUP BY keyword to split the aggregation into different groups, using the DATE_PART function in combination with the WHERE keyword to filter by a specific month/year combo
18. Day 18 - December 18th 2023: [Cities With Completed Trades from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day18.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using the INNER JOIN keyword to combine two tables on a common column, aggregating with the COUNT() function, using the GROUP BY keyword to split the aggregation into different groups
19. Day 19 - December 19th 2023: [App Click-Through Rate (CTR) from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day19.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using a CASE statement within a calculation to engineer new a feature, using the ROUND() function to give output a uniform number of decimals, using the DATE_PART function and the WHERE keyword to filter to a specific year, using the GROUP BY keyword to group the aggregation by app
20. Day 20 - December 20th 2023: [Medium Sized Countries from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day20.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the BETWEEN keyword in combination with the WHERE keyword to filter to countries that have a population within the specified range. Used the ORDER BY keyword to order by population
21. Day 21 - December 21st 2023: [Million Dollar Store from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day21.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the ROUND() function to round output to two decimal places, used the HAVING keyword to filter on the average revenue, and used the GROUP BY keyword to group yearly revenue by store. Used the ORDER BY keyword to order by store id
22. Day 22 - December 22nd 2023: [Big Countries from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day22.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the OR keyword to filter to countries that met at least one of the specified conditions in the WHERE clause, used the ORDER BY keyword to order by country alphabetically
23. Day 23 - December 23rd 2023: [Low Quality YouTube Video from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day23.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation with pre-existing fields to engineer a new feature, the like percentage of a video. I then filtered on the like percentage by using the WHERE keyword and used the ORDER BY keyword to order the output by video id
24. Day 24 - December 24th 2023: [Cards Issued Difference from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day24.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using the MIN() and MAX() functions to perform calculations with aggregations, using the GROUP BY keyword to split aggregations up into groups
25. Day 25 - December 25th 2023: [Compressed Mean from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day25.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Performing calculations to engineer new features, using the ROUND() function to round output, using the CAST() function to convert values into different data types
26. Day 26 - December 26th 2023: [Average Post Hiatus from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day26.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using the DATE_PART function to deal with time series data, using the ::date syntax to quickly change the data type of a timestamp variable to date, using the HAVING keyword to filter on aggregated data
27. Day 27 - December 27th 2023: [Second Day Confirmation from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day27.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Performing an INNER JOIN to combine data from two different tables, using the PostgreSQL Interval function to add a specified time interval to a date value
28. Day 28 - December 28th 2023: [Device First Used from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day28.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the GROUP BY keyword and the MIN() function to find the earliest date a game was played grouped by device. Used the WHERE keyword to filter by game and the ORDER BY keyword to order by the date
29. Day 29 - December 29th 2023: [Tesla Models from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day29.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation to engineer a new feature, the profit made selling a car. Used the ORDER BY and LIMIT keywords to grab the record with the highest profit
30. Day 30 - December 30th 2023: [The Blunder from HackerRank](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day30.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using the CEIL() function to round output up to the nearest whole number, using the REPLACE() function to remove all zeros from a field for the purpose of fixing a miscalculation
31. Day 31 - December 31st 2023: [The PADS from HackerRank](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day31.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Using the CONCAT() function to concatenate strings and variables in SQL

</details>


### January 2024

<details>

<summary>January 2024 Practice Problems</summary>

<br>

1. Day 32 - January 1st 2024: [Profit Margin from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day32.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation with existing fields to engineer a new feature, the profit margin for each product. Used the ROUND() keyword to format the numbers to a uniform number of decimals, and used the ORDER BY keyword to order by profit descending and product name ascending
2. Day 33 - January 2nd 2024: [On The Way Out from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day33.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the ORDER BY and LIMIT keywords together to only output the three oldest employees working at a company
3. Day 34 - January 3rd 2024: [Area Code from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day34.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the LEFT() function in combination with the WHERE keyword to filter to phone numbers that start with a specified area code
4. Day 35 - January 4th 2024: [Most Reviewed Restaurant from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day35.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the COUNT() function to count the number of comments and the AVG() function to find the average rating. Used the GROUP BY keyword to group by restaurant, used the ORDER BY keyword to order by comment count and average rating descending, and used the LIMIT keyword to only output the most reviewed restaurant
5. Day 36 - January 5th 2024: [Rotten Drama from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day36.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Calculated the difference between Rotten Tomato ratings and user ratings, then used the ABS() function to make all output positive. Used the ORDER BY and LIMIT keywords together to select the biggest rating difference
6. Day 37 - January 6th 2024: [Car Failure from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day37.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the AND keyword in combination with the WHERE keyword to filter on multiple conditions. Used the ORDER BY keyword to order by name alphabetically
7. Day 38 - January 7th 2024: [Best Classes from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day38.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the AVG() function to calculate the average grade, then used the GROUP BY keyword to group by class. Used the ORDER BY keyword to order by the average grade descending
8. Day 39 - January 8th 2024: [Homes Built from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day39.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the AND keyword in combination with the WHERE keyword and inequalities to filter on multiple conditions
9. Day 40 - January 9th 2024: [Higher Than 75 Marks from HackerRank](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day40.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using the RIGHT() function in combination with the the ORDER BY keyword to sort query output based off a specific part of a string
10. Day 41 - January 10th 2024: [Costco Rotisserie Loss from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day41.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the SUM() function to find the total revenue lost and used the ROUND() function to round to the nearest whole number
11. Day 42 - January 11th 2024: [Senior Citizen Discount from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day42.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Using the TIMESTAMPDIFF() function to find the difference between two dates, which I then used to filter to customers over a certain age
12. Day 43 - January 12th 2024: [Baseball Scouts from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day43.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used a CASE statement to make a skill level column that assigns players a level based on their batting average
13. Day 44 - January 13th 2024: [Men vs Women from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day44.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the AVG() function to calculate the average purchase price and the ROUND() function to round the output to 2 decimal places. Used the GROUP BY and ORDER BY keywords to group and order by gender
14. Day 45 - January 14th 2024: [Obesity from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day45.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the POWER() function and a formula to calculate BMI, used the ROUND() function to round the output to 2 decimal places. Then used the HAVING keyword to filter on BMI
15. Day 46 - January 15th 2024: [Pharmacy Analytics (Part 1) from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day46.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation to engineer a new feature, used ORDER BY in combination with LIMIT to output only the top three records
16. Day 47 - January 16th 2024: [Pharmacy Analytics (Part 2) from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day47.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used a combination of aggregations, filtering, grouping, and ordering to find out which drug manufacturers give CVS the most losses, along with the number of drugs produced by the manufacturer that are associated with losses. Also used the ABS() function to get the total losses as a positive number
17. Day 48 - January 17th 2024: [Pharmacy Analytics (Part 3) from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day48.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Calculated the total sales for CVS drugs grouped by manufacturers, used the CONCAT() and ROUND() function to give the output a uniform and easily readable format
18. Day 49 - January 18th 2024: [Sandwich Generation from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day49.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the CROSS JOIN keyword to combine each row of one table with each row of a second table, which allowed me to find each possible sandwich combination with the provided ingredients
19. Day 50 - January 19th 2024: [Separation from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day50.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: In this question, user ID's and user first names were accidentally combined into one string. I used the LEFT() function to make a separate field for the ID's, and used the SUBSTRING() function to make a separate field for the names
20. Day 51 - January 20th 2024: [Unique from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day51.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using the DISTINCT keyword to only grab unique values from a column, using the ORDER BY keyword to sort the output
21. Day 52 - January 21st 2024: [Food Divides Us from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day52.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the GROUP BY keyword, ORDER BY keyword, and LIMIT keyword to group fast food spending by region, order the output based on total fast food spending per region, and grabbing the top spending region
22. Day 53 - January 22nd 2024: [2022 Orders from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day53.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the INNER JOIN keyword to join two datasets on common columns, filtered by multiple conditions in the WHERE clause, used the YEAR() fuction to extract the year from a date for filtering purposes
23. Day 54 - January 23rd 2024: [Bad Bonuses from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day54.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used a subquery in the WHERE clause to filter to instances where a value in one table didn't exist in a second table, identifying employees that didn't receive bonuses
24. Day 55 - January 24th 2024: [Pepperoni-flation from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day55.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation in the SELECT statement combined with using the WHERE keyword to calculate how much money a pizza restuarant would save by putting less pepperoni on their pizzas
25. Day 56 - January 25th 2024: [Kroger's Members from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day56.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation in the SELECT statement to calculate the percentage of Kroger shoppers that have a membership card, used the ROUND() function to round to two decimal places
26. Day 57 - January 26th 2024: [Bike Price from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day57.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation in the SELECT statement to calculate the average sale price for bikes, using the IS NOT NULL keyword in the WHERE clause to exclude bikes that were donated so that it doesn't throw off the calculation, used the ROUND() function to round to two decimal places
27. Day 58 - January 27th 2024: [Water Pollution from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day58.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the GROUP BY keyword to group average pollution concentration by pollutant, used the HAVING keyword to filter on the aggregation, used the ROUND() function to round to two decimal places
28. Day 59 - January 28th 2024: [Company Wide Increase from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day59.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used a CASE statement to engineer a new feature that determines the new salary for each employee depending on the pay level they were on
29. Day 60 - January 29th 2024: [LinkedIn Famous from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day60.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation to determine the populatiry score of LinkedIn posts based off their impressions and interactions, filtered and sorted by the popularity score to get posts only of a specified popularity level
30. Day 61 - January 30th 2024: [Intern Problems from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day61.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used a CASE statement to edit certain values in a column, making the column have uniform formatting throughout
31. Day 62 - January 31st 2024: [Big Pharma from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day62.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the ABS() function to get the absolute value of money lost, then filtered to drugs that had a negative profit and returned the three drugs that lost the most money - there ended up being only two drugs that had lost money, so the final output table had two drugs

</details>


### February 2024

<details>

<summary>February 2024 Practice Problems</summary>

<br>

1. Day 63 - February 1st 2024: [Buying Less from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day63.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the GROUP BY keyword to group all orderS by customer id, then used the HAVING keyword to filter on total amount of money spent and total number of orders made with the purpose of targeting advertising to customers that don't spend as much
2. Day 64 - February 2nd 2024: [Greenhouse Gases from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day64.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed an aggregation to calculate total carbon emissions and used the ROUND function to make the output uniform, used the GROUP BY keyword to group the total emissions by country, then used the ORDER BY and LIMIT keywords to find the country with the most carbon emissions
3. Day 65 - February 3rd 2024: [Richie Rich from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day65.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the GROUP BY keyword to group total profit buy company, used the HAVING keyword to filter on the total profit aggregation, used the DATE_SUB function to filter to profit within a few years of a specified date
4. Day 66 - February 4th 2024: [Crew Overspending from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day66.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed an aggregation to calculate total spending, used a CASE statement to code different outputs based on the amount of spending, used the GROUP BY keyword to group the spending by employee
5. Day 67 - February 5th 2024: [Perfect Data Analyst from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day67.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used a combination of the AND, OR, and IS NOT NULL operators in the WHERE clause to identify candidates that met specific qualifications
6. Day 68 - February 6th 2024: [Gmail Users from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day68.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the SQL LIKE keyword and the wildcard character % to select all users who use Gmail as their email provider, AKA all emails that end in @gmail.com
7. Day 69 - February 7th 2024: [Average Gaming Session from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day69.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the AVERAGE function along with the WHERE keyword to find average time spent on gaming, used the GROUP BY keyword to group the results by user id
8. Day 70 - February 8th 2024: [Uber High and Low from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day70.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the OR keyword in combination with the WHERE keyword to filter on two separate conditions, used the ORDER BY keyword to order the output on income
9. Day 71 - February 9th 2024: [A/B Students from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day71.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the OR keyword in combination with the WHERE keyword to filter to students who got an A or B for their final exam, used the ORDER BY keyword to order the output alphabetically
10. Day 72 - February 10th 2024: [Football Perfection from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day72.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the AND keyword in combination with the WHERE keyword to filter to football teams that had both a high number of points scored and a low number of penalties
11. Day 73 - February 11th 2024: [Animals from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day73.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the UNION keyword to combine two datasets with common columns and remove any duplicates, used the ORDER BY keyword to order output alphabetically
12. Day 74 - February 12th 2024: [Electric Bike Replacement from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day74.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the WHERE keyword to filter to eletric bikes that need to be replaced due to a high level of battery usage, then used the COUNT() function to count how many bikes need to be replaced
13. Day 75 - February 13th 2024: [Chocolate from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day75.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the WHERE keyword in combination with the LIKE keyword to select all items that have the word chocolate anywhere in their name
14. Day 76 - February 14th 2024: [Average Revenue from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day76.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the AVG() function to find average revenue, used the GROUP BY keyword to group the average revenue by store, then used the ORDER BY keyword to order by average revenue so the top earning stores showed at the top of the output table
15. Day 77 - February 15th 2024: [Apply Discount from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day77.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the WHERE keyword in combination with the OR keyword to filter to customers that met the conditions for receiving a discount, then used the COUNT() function to count the number of customers that met the conditions
16. Day 78 - February 16th 2024: [Web Traffic from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day78.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the COUNT(DISTINCT) function to count the number of unique visitors on a website, used the GROUP BY keyword to group the visitors by date
17. Day 79 - February 17th 2024: [Product Launch from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day79.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used CASE statements and the COUNT() function together to count the number of product launches in 2022 and 2023, then performed subtraction to find the difference in the number of product launches between the two years. Used the GROUP BY keyword to group the difference by company, and used the ORDER BY keyword to order the output alphabetically
18. Day 80 - February 18th 2024: [Multi-Level Marketing from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day80.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the SUM() aggregation to add up total profits, used the MONTH() function to extract the month from a date field, then used the GROUP BY keyword to group the profits by month. Used the HAVING keyword to filter to the first half of the year and to months where the sum of the profit was greater than zero, then used the ORDER BY keyword to order by profit
19. Day 81 - February 19th 2024: [Football Attendance from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day81.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the SUM() aggregation to add up total season attendance, used the GROUP BY keyword to group the attendance by season, then used ORDER BY and LIMIT together to only output the season with the top attendance
20. Day 82 - February 20th 2024: [Tech Layoffs from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day82.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation to find the percentage of the company that got laid off from their job and used the ROUND() function to clean up the output into a uniform number of decimals. Used the GROUP BY keyword to get the percentage of the company laid off for each company in the dataset
21. Day 83 - February 21st 2024: [Cloud Storage Fees from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day83.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation to see which users had gone over their alloted 200gb of cloud storage so that they could pay a fee, used the ABS() function to get the result in absolute value rather than negative
22. Day 84 - February 22nd 2024: [Must Buy it All from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day84.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the HAVING keyword in combination with the COUNT(DISTINCT) keyword to filter to customers that had bought all of a company's products, used the GROUP BY keyword to group the product count by each customer
23. Day 85 - February 23rd 2024: [Computer Replacement from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day85.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the MySQL DATE_SUB() function in combination with the WHERE keyword to filter to computers that were bought over five years ago so they can be replaced
24. Day 86 - February 24th 2024: [SuperCoolElectronicsStore.com from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day86.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the LIKE keyword along with the wildcard character % to find laptop names that mentioned SSD storage or HDD storage, then used a CASE statement to engineer a new column that holds the storage type
25. Day 87 - February 25th 2024: [Media Addicts from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day87.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed an INNER JOIN to combine two datasets with information about how much time a user spent on social media and the name of each user. Then used the WHERE keyword in combination with a small subquery to filter to users that spent more time on social media than average, returning the first name of users with above average usage in alphabetical order with the help of the ORDER BY keyword
26. Day 88 - February 26th 2024: [Ranking Students from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day88.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the DENSE_RANK() function to assign students a rank number based on their grade, assigning students with the same grade value the same rank number. Used the ORDER BY keyword to order by both ranks descending and names alphabetically, that way students with the same ranks still have a defined order
27. Day 89 - February 27th 2024: [TMI (Too Much Information) from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day89.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the SUBSTRING_INDEX() function to split a field with customer's first and last names into two based on the position of the space, then returning the first half of the string to only select first names
28. Day 90 - February 28th 2024: [Movie-aholic from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day90.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the INNER JOIN keyword to join two tables with customer data and data on the movies they watched. Used the ORDER BY keyword in combination with the COUNT() keyword to order output by the number of movies descending, using the GROUP BY keyword to group the number of movies by each customer. Then used the LIMIT keyword to only return the name of the customer that had watched the most movies
29. Day 91 - February 29th 2024: [Employee Turnover from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day91.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used a CASE statement in combination with the YEAR() function and COUNT() function to count instances where employees left the company in 2022. Then divided by the total number of employees and multiplied by 100 to calculate the employee turnover rate for the year of 2022

</details>


### March 2024

<details>

<summary>March 2024 Practice Problems</summary>

<br>

1. Day 92 - March 1st 2024: [Full Time Jobs from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day92.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Combined two datasets on job data using the UNION keyword. Then used the union as a subquery so I could count the number of rows in the combined table. Used the WHERE and HAVING keyword together to filter to instances where an employee had two full-time jobs, then used the GROUP BY keyword to group the instances by employee name
2. Day 93 - March 2nd 2024: [Boss from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day93.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed a self join to get employee names and boss names on the same row for the purpose of finding the boss for each employee, a LEFT JOIN specifically to keep all employee data even if they don't have a boss. Used the ORDER BY keyword to get the output in alphabetical order
3. Day 94 - March 3rd 2024: [Direct Reports from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day94.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed a self join to tie the employee ids to the manager ids. Used the LIKE keyword and the wildcard character % in the WHERE clause to filter to positions that had the word manager anywhere in its name. Then performed a COUNT() on the number of times each manager id showed up and used the GROUP BY keyword to group by manager id and position, finding the number of direct reports for each manager
4. Day 95 - March 4th 2024: [Amazon Returns from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day95.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the GROUP BY keyword to group by order id - each product bought had its own row even if they were part of the same order, so this was necessary to look at the order total as a whole rather than by each item. Then used the HAVING keyword in combination with the SUM() function to filter to instances where the potential profit of the entire order was less than the estimated return price of the entire order
5. Day 96 - March 5th 2024: [Employee Raise from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day96.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Started by writing a query that used the MIN() function to select the lowest salary, then used the GROUP BY keyword to get the lowest salary by department. Used this query as a subquery for a JOIN, joining the query with the employee data on the department and salary fields. Then performed a calculation to determine the new salaries for the lowest paid employee in each department, using the ORDER BY keyword to sort the output by largest new salary to smallest new salary
6. Day 97 - March 6th 2024: [Who Made Quota? from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day97.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Started off by using the INNER JOIN keyword to join data on sales and assigned sales quotas. Then used a CASE statement to engineer a new column to determine if each salesperson met their quota
7. Day 98 - March 7th 2024: [Duplicate Job Listings from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day98.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Wrote a query that used the COUNT() function to count the number of jobs, then used the GROUP BY keyword to group by company id, job title, and job description to find instances where there were duplicate job listings. Used that query as a subquery to count the number of companies WHERE they have duplicate listings
8. Day 99 - March 8th 2024: [Movie-aholic (Joins) from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day99.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: This is an alternate version of the Movie-aholic practice problem I completed on Day 90 - this version of the problem focuses on joining multiple tables. I performed an INNER JOIN twice to get data from three different tables into one output table, then outputted the name of the customer, the movie they watched, and what date they watched it on
9. Day 100 - March 9th 2024: [Running Total from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day100.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: In this problem I used a window function to find a running total of points for each gender over multiple days. I found the SUM() of the points, used PARTITION BY to group on the gender, then used the ORDER BY keyword within the window function to order by the date. I then also ordered by the points within the window function to find the running total of points
10. Day 101 - March 10th 2024: [Breaking Out Column from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day101.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the SUBSTRING_INDEX() function, including nested SUBSTRING_INDEX() functions, to break out an address field into separate street, city, state, and zip code columns. Used the TRIM() function to clear up any white space inconsistencies
11. Day 102 - March 11th 2024: [Contact Information from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day102.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Performed an INNER JOIN to connect customer data to their contact data. Used a CASE statement to find instances where the user's email was NULL in the contact table so we could create an email for them. It was specified that the user's email should be their first name combined with their last name with a gmail domain in all lowercase, so I used the CONCAT() function, the LOWER() function, and customer data to create email addresses for anyone missing one
12. Day 103 - March 12th 2024: [Art Ranking from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day103.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the RANK() window function to assign ranks to artists based on their total score across three judges. The SUM() function was used to calculate each artists' total score, then the total score was used in the window function to order the output descending, ensuring that the artists with the highest points were ranked first
13. Day 104 - March 13th 2024: [Fire Them! from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day104.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using the AND keyword in the WHERE clause to filter on multiple conditions and writing a formula to calculate the percentage of tasks that each employee has completed
14. Day 105 - March 14th 2024: [Help Desk Manager from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day105.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used a CASE() statement in combination with the SUM() function to add up the number of calls that had been resolved, then used the COUNT() function to divide by the total number of calls and multiplied by 100 to get the result as a percentage. Lastly, I used the GROUP BY keyword and grouped by employee name to view the percentage of calls each employee resolved over the total number of calls they've taken
15. Day 106 - March 15th 2024: [Unions from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day106.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the UNION ALL keyword to combine medication and dosage information from two tables, keeping duplicates. Used the ORDER BY keyword to order the output alphabetically
16. Day 107 - March 16th 2024: [Salary By Department from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day107.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the AVG() function to find the average salary, then used PARTITION BY within a window function to compare each person's salary to the AVG() salary of their department. I then ordered by department alphabetically and salary descending to order each department from their highest earners to their lowest earners
17. Day 108 - March 17th 2024: [Temperature Fluctuations from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day108.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the LAG() window function to get the previous date's temperature next to the current date's temperature in the output table. Then used that query as a subquery and selected the dates from that query only when the current date's temperature was greater than the previous date's temperature
18. Day 109 - March 18th 2024: [Kelly's 3rd Purchase from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day109.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the ROW_NUMBER() window function, then used PARTITION BY to split it up by customer id and used ORDER BY to order it by transaction id ascending, making sure each customer's purchases were in sequential order. That query now assigned a row number to each purchase a customer made, so I used it as a subquery and had the outer query only grab the third order from each customer, performing a calculation to apply a discount to each third order
19. Day 110 - March 19th 2024: [Right Twix vs Left Twix from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day110.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Performed a calculation to see what percentage of consumers voted for right twix or left twix. Divided each side by the total number of votes and multiplied by 100 to get it as a percentage, then used the ROUND() function to round the output to 2 decimal places
20. Day 111 - March 20th 2024: [Good Dog Bad Owner from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day111.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used a CASE statement to see if dog owners had walked their dogs enough to be considered a good owner. If they had multiple dogs, they must have walked both enough to be considered a good owner. Achieved this by finding the SUM() of all walks grouped by owner name and dog name to see how much each owner had walked each dog over the week. Then used that query as a subquery to check the MIN() of total walks - that way owners who had walked one of their dogs enough but not their other dogs enough would be labelled as bad owners by the CASE statement
21. Day 112 - March 21st 2024: [Highest Grade from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day112.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the ROW_NUMBER() window function in combination with the PARTITION BY keyword to group by student and the ORDER BY keyword to order by grade descending and class id ascending. This allowed me to get the top grades for each student as row number 1, and when a tie in grades happened it would be based on the lowest class id. I then used that query as a subquery to filter to instances where the row number was 1, allowing me to select the top grade and its corresponding subject and class id for each student
22. Day 113 - March 22nd 2024: [2nd Highest from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day113.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Started by using the INNER JOIN keyword to join the departments and employees tables on department id. I then used the ROW_NUMBER() window function in combination with the PARTITION BY keyword to group by department and the ORDER BY keyword to order by salary descending. I used that query as a subquery and filtered to instances where the row number was 2, allowing me to select the second highest earner in each department
23. Day 114 - March 23rd 2024: [Unfair Taxation from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day114.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used a window function in combination with the PARTITION BY keyword to SUM() up the total salary for each company, then used the query as a subquery. In the outer query I wrote a case statement to tax employee salaries depending on the total salary for their respective companies
24. Day 115 - March 24th 2024: [Investment Properties from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day115.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Started by calculating profit on home sales by subtracting the purchase price from the sale price. I then used that query as a subquery and used a window fuction to get a rolling total for the SUM() of profit
25. Day 116 - March 25th 2024: [Hotel Guests from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day116.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the COUNT() function to count the number of check outs. Used the WHERE keyword in combination with the MySQL TIME() function to filter to checkouts that happened after 10am, the checkout time. The final query counted the number of guests that checked out late
26. Day 117 - March 26th 2024: [Approved Transactions from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day117.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the MONTH() function to extract the month from a date field. Used multiple CASE() statements to find the number of approved transactions and the total amount of money approved as well as the number of denied transactions and the total amount of money denied. Used the GROUP BY keyword to group by month and country so that each month from each country had its own row
27. Day 118 - March 27th 2024: [Help Requests from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day118.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used multiple CASE statements to count the number of completed requests, count the number of incomplete requests, and calculate the percentage of completed requests. I then used the GROUP BY keyword to group by request type, allowing us to break down the counts and percentage within each type of request
28. Day 119 - March 28th 2024: [Inactive Accounts from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day119.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Started by writing a query that selects the user id of users that had been active recently. Used that as a subquery in the WHERE clause to find user ids that were not in the list of active users. Used the GROUP BY keyword to group by user id so that each inactive user id only showed up once in the output table
29. Day 120 - March 29th 2024: [Customer Transactions from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day120.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Wrote a query that uses the SUM() function to calculate the total money spent and the GROUP BY function to group by customer id. Then used the RANK() window function to rank each customer by their spending and used the ORDER BY keyword to order on the total sales, the rank number, and the customer id. I then used that entire query as a subquery and filtered to rows where the rank number was 1, 2, or 3
30. Day 121 - March 30th 2024: [JANINE!! from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day121.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used regular expression, more specifically the REGEXP_REPLACE() function, to remove any non-alphanumeric characters from the product name. Then used that query as a subquery so I could fix the capitalization of the fixed product names. I used the MySQL UCASE() function in combination with the LEFT() function to capitalize the first letter, used the LCASE() function in combination with the SUBSTRING() function to make the rest of the word after the first letter lowercase, then used the CONCAT() function to combine them into the full product name
31. Day 122 - March 31st 2024: [Chef Malpractice from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day122.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the SUM() function in combination with the CASE() function to add up the number of orders that were returned to the kitchen, then used the GROUP BY keyword to group by chef. Afterwards, I used the RANK() window function and nested it with the CASE() function to order by the number of returned orders descending. I then used that entire query as a subquery and used the WHERE keyword to filter the rank number to 1, allowing me to select the chef with the most food sent back to the kitchen
    
</details>


### April 2024

<details>

<summary>April 2024 Practice Problems</summary>

<br>

1. Day 123 - April 1st 2024: [Twitter Addiction from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day123.md)
    - Languages Used: SQL
    - Question Difficulty: Very Hard
    - Concepts Covered: Used the TIMESTAMPDIFF() and LAG() window function together to find the time between posts for Twitter users. I used that query as a subquery and utilized the AVG() function to find the average amount of time between posts for each user
2. Day 124 - April 2nd 2024: [Domain Knowledge from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day124.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the SUBSTRING_INDEX function twice, first to split on the @ symbol and second to split on the . symbol, which allowed me to select only the domain for each email address. Then I used that query as a subquery, and in the outer query I used the COUNT() function and the GROUP BY keyword to see how many times each domain appeared in the dataset
3. Day 125 - April 3rd 2024: [Returning Customers from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day125.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the MySQL DATEDIFF() function and the LAG() window function together to find out how long customers took to place a new order relative to their previous order. I used that query as a subquery and in the outer query I used the WHERE keyword to filter to where the number of days between purchases was less than or equal to 5, then used the GROUP BY keyword to group by user id
4. Day 126 - April 4th 2024: [Basketball Greatness from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day126.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the DENSE_RANK() window function to rank basketball players based on total points scored. The question specified that in case of a tie the next rank should be the next consecutive integer, which is how I knew to use DENSE_RANK() over RANK()
5. Day 127 - April 5th 2024: [Merry Facebook from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day127.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the RANK() window function to rank Facebook actions (such as comments, likes, etc.) based on how many times they were performed. Used the WHERE keyword to filter the date to Christmas day to look at only Christmas actions and used the GROUP BY keyword to group the count of actions by each action type
6. Day 128 - April 6th 2024: [Name Format from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day128.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used a combination of the LEFT() function, SUBSTRING() function, UPPER() function, and LOWER() function to fix the capitalization of name fields and put them in Proper Case, with the first letter capitalized and everything else lowercase. I then used the CONCAT() function to create a field that holds the full name in Proper Case
7. Day 129 - April 7th 2024: [Job Search from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day129.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used a combination of the AND keyword, the OR keyword, the LIKE keyword, the wildcard character %, and the SUBSTRING_INDEX() function in the WHERE clause to perform complex filtering on job postings. I filtered on job title, required skills, and salary
8. Day 130 - April 8th 2024: [Cake vs Pie from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day130.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used CASE statements to add up the number of cakes and pies sold, then used the GROUP BY keyword to group by date and view how many were sold each day. I then made another CASE statement to output which dessert was more popular for each date and calculated the difference in the number of products sold
9. Day 131 - April 9th 2024: [Internet Outages from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day131.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the STR_TO_DATE function to convert the data type of the date fields from strings to dates. Then used the AVG() and TIMESTAMPDIFF() function to calculate the average number of minutes that an internet outage lasts, using the GROUP BY keyword to group by each ISP. I also used a CASE statement to add up cases where the end date of the outage IS NULL, meaning that the outage is still ongoing
10. Day 132 - April 10th 2024: [Lyft Bonuses from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day132.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used a CASE statement to calculate bonuses for each Lyft driver depending on the number of rides they completed - $100 for 100 rides, $500 for 500 rides, $1000 for 1000 rides, and an extra $1000 for each 1,000 rides afterwards. I used the FLOOR() function within a calculation to round the rides to the lowest thousand - so a driver with 7,500 rides would be counted as having 7000 rides to calculate the bonus for the last thousand they reached
11. Day 133 - April 11th 2024: [Price Check from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day133.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the SELECT, GROUP BY, and WHERE keywords to select the MAX() of the date for each product before or on a certain date, grouped by product id. Then used that query as a subquery and selected the product id and price and did an INNER JOIN on the subquery output table and the base table. I joined on product id and the date from the main table being equal to the MAX() date from the subquery table, finding the most recent product price
12. Day 134 - April 12th 2024: [Consecutive Visits from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day134.md)
    - Languages Used: SQL
    - Question Difficulty: Very Hard
    - Concepts Covered: Started off by creating a CTE. Within the CTE, I joined the two datasets on customer id, selected all the columns, and used the DATEDIFF() function to find the difference between the visit date and the last visit date. The last visit date was calulated using the LAG() window function on visit date, using the PARTITION BY keyword to group by customer id and the ORDER BY keyword to order on the visit date. I then made a query that selected everything from that CTE, along with a CASE() statement that used the SUM() function to add up cases where the days between visits were equal to 1, meaning the visit was consecutive. I also had to add 1 to the CASE statement's results to count the first visit. With all that done, I used that query as a subquery to grab the MAX() of the consecutive visits
13. Day 135 - April 13th 2024: [Biggest Spenders from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day135.md)
    - Languages Used: SQL
    - Question Difficulty: Very Hard
    - Concepts Covered: Started off by creating a CTE to join the two datasets on customer id, selected all the columns, and used the MONTH() function to extract the month from the purchase date column. I then made a query that selected everything from that CTE, while also calculating the total spending and row numbers. The total spending was calculated by using the SUM() function and using the GROUP BY keyword to group by month and customer. The row number was calculated with the ROW_NUMBER() window function, using the PARTITION BY and ORDER BY keywords to assign the highest spenders per month to row number 1. I then used that query as a subquery to grab the records WHERE the row number was equal to 1, selecting only the biggest spenders for each month
14. Day 136 - April 14th 2024: [NASCAR Times from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day136.md)
    - Languages Used: SQL
    - Question Difficulty: Very Hard
    - Concepts Covered: Started off by creating a CTE that used the DENSE_RANK() window function to give a ranking number to the laps based on their times. I then made a query that selects rank numbers 1, 2, 3, 21, 22, and 23 to filter to the three fastest and three slowest times. I used the GROUP BY keyword to group by lap time, which got rid of any duplicates. I then used a CASE statement to label the laps the fastest laps or slowest laps based on their rank number. I then used that query as a subquery and used the RANK() window function to PARTITION BY label and rank the fastest and slowest laps separately. I needed to order the slowest laps descending and the fastest laps ascending, so I used a CASE statement to rank the lap times differently based on their label. Finally, I used the ORDER BY keyword to order by label descending and ranking ascending to get the desired format for the output
15. Day 137 - April 15th 2024: [Complex Address from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day137.md)
    - Languages Used: SQL
    - Question Difficulty: Very Hard
    - Concepts Covered: Used the SUBSTRING_INDEX() function to convert an address stored in one field to separate fields for the street, city, state, and postal code. I used a CASE statement for the street address to ensure that unnecessary information such as the unit or suite numbers are removed. I also used the TRIM() function to remove any extra whitespace from the data, ensuring consistent formatting
16. Day 138 - April 16th 2024: [Uber Cancellation Rates from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day138.md)
    - Languages Used: SQL
    - Question Difficulty: Very Hard
    - Concepts Covered: Started off by creating a CTE to filter and join the data. I had to use the JOIN keyword twice, once to join the client ids with the user ids and once to join the driver ids with the user ids. I also made sure to filter to only unbanned users and to the dates specified in the question. I selected from that CTE for my query, where I added up cancelled rides, divided by all rides, and multiplied by 100 to calculate the cancellation rate. To calculate the cancelled rides I used the SUM() function and a CASE statement together to add up the rides where the status was not equal to completed, and I just used the COUNT() function on a field to get the total rides. I ended off the query by using the ROUND() function to round the percentage to 2 decimals and used the GROUP BY keyword to group by the date, getting a separate percentage for each date in the date range
17. Day 139 - April 17th 2024: [Employee Hierarchy from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day139.md)
    - Languages Used: SQL
    - Question Difficulty: Very Hard
    - Concepts Covered: I used a recursive CTE to complete this problem. I grabbed the employee id from the hierarchy table and made a field named level with a numeric value of 1, then used the WHERE keyword to filter to instances where the supervisor id IS NULL. The very top employees don't have supervisors, so that assigned those employees to level 1. I then used the UNION ALL keyword, and in the next query I grabbed employee id again and added 1 to the level. I joined the hierarchy table and the employeehierarchy CTE where the supervisor id from the hierarchy table was equal to the user id from the employeehierarchy CTE, which assigned each employee a level number based on who their supervisor is - people with no supervisor were a level 1 employee, people with a level 1 supervisor were level 2 employees, and so on. With that recursive CTE complete, I made a query to grab the employee id and level field from the completed employeehierarchy CTE and used the ORDER BY keyword to order by employee id
18. Day 140 - April 18th 2024: [Inflation from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day140.md)
    - Languages Used: SQL
    - Question Difficulty: Very Hard
    - Concepts Covered: Started by creating a CTE where I selected the country, the consumer price index field to grab the current inflation rate, and the previous consumer price index to grab the previous inflation rate. The previous inflation rate was calculated with the LAG() window function, using the PARTITION BY and ORDER BY keywords to group by country and order by year. I then used that CTE to find the average inflation rate. The average inflation rate was calculated by subtracting the previous inflation rate from the current inflation rate, dividing by the previous inflation rate, multiplying by 100, then using the AVG() function to average it all. I then used the RANK() window function to rank the countries based on their average inflation rate and ordered by the rank number
19. Day 141 - April 19th 2024: [Sending vs. Opening Snaps from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day141.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Created a CTE that used the INNER JOIN keyword to join the activities and age breakdown tables on the user id. In the CTE I also used CASE statements to add up time spent based on whether the activity type was sending Snapchats or opening Snapchats, then used the GROUP BY keyword to group the time spent on each activity by age group. I then used that CTE to perform a calculation that finds how much time was being spent on the sending vs. opening rates as a percentage total of time spent on both activities. I finished up the query by using the ROUND() function to round the percentages to two decimal places
20. Day 142 - April 20th 2024: [Odd and Even Measurements from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day142.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Created a CTE that grabbed the measurement values, the DATE_TRUNC() of the date field aggregated to day, and the ROW_NUMBER() window function with a PARTITION BY the day. From that CTE I selected the measurement day, then used CASE statements to SUM() the measurement values based on whether or not the row number was even or odd. I tested this by using the modulo (%) operator on the row number, as any even number modulo 2 is 0 and odd numbers result in a 1. I finished up the query with the GROUP BY keyword to group by the day, resulting in the total even and odd measurements for each day in the dataset.
21. Day 143 - April 21st 2024: [User's Third Transaction from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day143.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the ROW_NUMBER() window function with a PARTITION BY user id, using the ORDER BY keyword to order by the transaction date and assign a row number to each user's transactions. I then used that query as a subquery and used the WHERE keyword to filter where the row number was equal to 3, grabbing each user's third order
22. Day 144 - April 22nd 2024: [Tweets' Rolling Averages from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day144.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the AVG() window function with a PARTITION BY user id, using the ORDER BY keyword to order by the tweet date ascending, resulting in a rolling average. I then used the ROWS BETWEEN keyword to only average the two preceding rows and the current row, making a rolling 3-day average. I finished off by using the ROUND() function to round the output to 2 decimal places
23. Day 145 - April 23rd 2024: [Histogram of Users and Purchases from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day145.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the RANK() window function with a PARTITION BY user id, using the ORDER BY keyword to order by the transaction date descending, resulting in the most recent transaction date for each user being assigned a rank number of 1. I then used the COUNT() function on the product id column to count the number of purchases since some customers made more than one purchase in a day. I used the WHERE keyword to filter the rank number to 1 and the GROUP BY keyword to group by transaction date and user id
24. Day 146 - April 24th 2024: [Highest-Grossing Items from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day146.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I started by creating a CTE. In the CTE, I used the SUM() function to find the total amount of money spent, then used the RANK() window function with a PARTITION BY item category, using the ORDER BY keyword to order by the SUM() of money spent descending. I used the DATE_PART function in the WHERE clause to filter to purchases that took place in 2022, then used the GROUP BY keyword to group by category and product. This put the top two products based on money spent for each category in 2022 at rank number 1 and 2. I then selected the category, product, and total money spent from the CTE and used the WHERE keyword to filter to the rank being 1 or 2
25. Day 147 - April 25th 2024: [Top 5 Artists from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day147.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I started by creating a CTE. In the CTE I used the INNER JOIN keyword twice, once to join the artists table with the songs table, and once to join the songs table with the global song rank table. I selected the artist name and used the DENSE_RANK() window function in combination with the ORDER BY keyword to give artists a rank based on the COUNT() of song id. I also used the WHERE keyword to filter to instances where the global song rank was 10 or lower, which means I only counted songs that reached the top 10 in global charts for each artist. I used the GROUP BY keyword to group by artist so that each artist only showed up once in the output table. With the CTE completed, I selected the artist name and artist rank from it, then used the WHERE keyword to filter the artist rank to 1, 2, 3, 4, and 5 to find the top 5 artists in terms of top 10 hits
26. Day 148 - April 26th 2024: [Patient Support Analysis (Part 1) from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day148.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: I used the SELECT keyword to grab the policy holder's id and COUNT() the case id field. I used the GROUP BY keyword to group by policy holder id and used the HAVING keyword to filter to instances where the COUNT() of the case id field was greater than or equal to 3. I then used that query as a subquery, and in the outer query I used the COUNT() function to count the number of policy holder id's. The output represented how many policy holders in the dataset made three or more calls about their health care needs
27. Day 149 - April 27th 2024: [Patient Support Analysis (Part 2) from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day149.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: The calls category column is either NULL or has a value of 'n/a' when the call is uncategorized, so I made a CASE statement in combination with the SUM() function to count the instances where a call was uncategorized. I then used the COUNT() function to tally the total number of calls. I used that query as a subquery, and in the outer query I calculated the percentage of uncategorized calls in the table, using the ROUND() function to round the output to 1 decimal place
28. Day 150 - April 28th 2024: [Signup Activation Rate from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day150.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Started by creating a CTE and joining the emails and texts table. I did a RIGHT JOIN to keep all records in the text table, that way when I used the COUNT() function it counted all the text data even if the user wasn't in the emails table. I also used a CASE statement with the SUM() function to tally the number of users that activated their account via text. With that CTE done, I divided the confirmed accounts by the total accounts and used the ROUND() function to round to 2 decimal places
29. Day 151 - April 29th 2024: [Compressed Mode from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day151.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Started by creating a CTE where I selected the item count, order occurrences, and used the RANK() window function to assign a rank to each row based on the order occurrences descending. With that CTE completed, I selected the item count from the CTE, then filtered to where the rank was equal to 1 to find the most popular item counts. I used the ORDER BY keyword to order by the item count ascending since two item counts tied for first place
30. Day 152 - April 30th 2024: [Card Launch Success from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day152.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Started by creating a CTE and using the RANK() window function with a PARTITION BY the card name and an ORDER BY the issue year ascending and the issue month ascending. This assigned every initial launch of a card a rank of 1, so I wrote a query that selected the card name and issued cards amount where the rank number was equal to 1, showing how many cards were issued in the first month for each credit card type

</details>


### May 2024

<details>

<summary>May 2024 Practice Problems</summary>

<br>

1. Day 153 - May 1st 2024: [International Call Percentage from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day153.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Started by creating a CTE and doing a LEFT JOIN twice, once to join caller id on caller id and once to join receiver id on caller id. This allowed me to find the location of every person in the dataset. I then used a CASE statement in combination with the SUM() function to check for instances where the caller's country is not equal to the receiver's country, meaning it's an international call. I also used COUNT() to count the total number of calls. With that CTE complete, I wrote a query that divided the international calls by the total calls and multiplied by 100 to get the international call percentage. I used the ROUND() function to round the output to 1 decimal place
2. Day 154 - May 2nd 2024: [Combine Two Tables from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day154.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .merge() function to join the employee names on the employee locations, being sure to keep all employee names even if they don't exist in the location table. Used the .sort_values() function to order by first name alphabetically, then selected the first name, last name, and state from the dataframe
3. Day 155 - May 3rd 2024: [Big GDP from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day155.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Performed dataframe filtering to filter by GDP and used the .sort_values() function to order by the country name alphabetically, then selected the country from the dataframe
4. Day 156 - May 4th 2024: [Shopping Cart Conversions from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day156.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation to engineer a new feature, specifically the percentage of items that customers put in their cart that they actually bought. Used the .round() function to round to two decimal places and the .sort_values() function to sort by customer id
5. Day 157 - May 5th 2024: [Most Orders from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day157.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .max() function to find the maximum number of orders and stored it in a variable. Then filtered the dataframe to records where the max number of orders was equal to the number of orders
6. Day 158 - May 6th 2024: [Duplicate Emails from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day158.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .count() function and the .groupby() function to count the number of emails and group by email, also used the .reset_index() function and .rename() function to name the new column email_count. I then filtered the dataframe on email_count to find instances where the email count was greater than 1, singling out users with duplicate emails. I used the .sort_values() function to order the output by email alphabetically
7. Day 159 - May 7th 2024: [Heart Attack Risk from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day159.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the & symbol and inequalities to filter on multiple conditions that would put a patient at risk of a heart attack. Used the .sort_values() function to order by cholesterol descending since that's the most important indicator
8. Day 160 - May 8th 2024: [Wealthy Customers from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day160.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Filtered the dataframe to customers that spent at least 500 dollars in a single order, then used the .nunique() function to count the unique number of customers
9. Day 161 - May 9th 2024: [Movie Theater from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day161.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the | operator to filter a dataframe on multiple values
10. Day 162 - May 10th 2024: [Ice Cream Popularity from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day162.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used comparison operators to compare two fields for the purpose of filtering a dataframe. Used the .sort_values() function to order the output by ice cream flavor alphabetically
11. Day 163 - May 11th 2024: [Gamer Tags from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day163.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used string slicing to select part of a string, the .split() function to select part of a date, and performed string concatenation using the + symbol. Used the .sort_values() function to order the output by gamer tag
12. Day 164 - May 12th 2024: [Medium Sized Countries from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day164.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the & operator in combination with inequalities to filter the dataframe to countries that have a population within the specified range. Used the .sort_values() function to order by population
13. Day 165 - May 13th 2024: [Million Dollar Store from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day165.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .groupby() function to group the dataframe by store id, the .mean() function to find the average revenue, and the .round() function to round the output to 2 decimal places. I then filtered the dataframe by revenue and used the .sort_values() function to order the dataframe by store id
14. Day 166 - May 14th 2024: [Big Countries from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day166.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the | symbol to filter the dataframe to countries that met at least one of the specified conditions, used the .sort_values() function to order by country alphabetically
15. Day 167 - May 15th 2024: [Low Quality YouTube Video from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day167.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation with pre-existing fields to engineer a new feature, the like percentage of a video. I then filtered the dataframe based on the like percentage and used the .sort_values() function to order the output by video id
16. Day 168 - May 16th 2024: [Device First Used from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day168.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .groupby() function and the .min() function to find the earliest date a game was played grouped by device. Filtered the dataframe by game and used the .sort_values() function to order by the date
17. Day 169 - May 17th 2024: [Tesla Models from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day169.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation to engineer a new feature, the profit made selling a car. Used the .sort_values() and .head() functions to grab the record with the highest profit
18. Day 170 - May 18th 2024: [Profit Margin from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day170.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation with existing fields to engineer a new feature, the profit margin for each product. Used the .round() function to format the numbers to a uniform number of decimals, and used the .sort_values() function to order by profit descending and product name ascending
19. Day 171 - May 19th 2024: [On The Way Out from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day171.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the pd.to_datetime() function to convert the birth date field to a datetime. I then used the .sort_values() and .head() functions together to only output the three oldest employees working at a company
20. Day 172 - May 20th 2024: [Area Code from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day172.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .str() function to perform string slicing with the purpose of filtering to phone numbers that start with a specified area code
21. Day 173 - May 21st 2024: [Most Reviewed Restaurant from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day173.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .transform() function on the comment column to count the number of comments and the .transform() function on the rating column to find the mean/average rating. Used the .groupby() function while calculating both of those to group by restaurant, used the .sort_values() function to order by comment count and average rating descending, and used the .head() function to only output the most reviewed restaurant
22. Day 174 - May 22nd 2024: [Rotten Drama from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day174.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Calculated the difference between Rotten Tomato ratings and user ratings, then used the abs() function to make all output positive. Used the .sort_values() and .head() functions together to select the biggest rating difference
23. Day 175 - May 23rd 2024: [Car Failure from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day175.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used inequalities to filter a dataframe on multiple conditions. Used the .sort_values() keyword to order by name alphabetically
24. Day 176 - May 24th 2024: [Best Classes from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day176.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .mean() function to calculate the average grade and the .groupby() function to group by class. Used the .sort_values() function to order by the average grade descending
25. Day 177 - May 25th 2024: [Homes Built from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day177.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the & symbol and inequalities to filter a dataframe on multiple conditions
26. Day 178 - May 26th 2024: [Costco Rotisserie Loss from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day178.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .sum() function to find the total revenue lost and used the .round() function to round to the nearest whole number. Also used the .astype() function in to convert the number from a float to an int and drop the decimal place
27. Day 179 - May 27th 2024: [Baseball Scouts from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day179.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the numpy .where() function to make a skill level column that assigns players a level based on their batting average
28. Day 180 - May 28th 2024: [Men vs Women from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day180.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .mean() function to calculate the average purchase price and the .round() function to round the output to 2 decimal places. Used the .groupby() and .sort_values() functions to group and order by gender
29. Day 181 - May 29th 2024: [Obesity from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day181.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used a formula to calculate BMI, which included the use of the ** symbol to calculate a power. Used the .round() function to round the output to 2 decimal places and filtered the dataframe based on BMI
30. Day 182 - May 30th 2024: [Perfect Data Analyst from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day182.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Checked the fields for a certain value to determine if a candidate met specific job qualifications and used the & and | comparison operators to filter the data frame
31. Day 183 - May 31st 2024: [Chocolate from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day183.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .str() function in combination with the .contains() function to filter the dataframe to all items that have the word chocolate anywhere in their name

</details>



### June 2024

<details>

<summary>June 2024 Practice Problems</summary>

<br>

1. Day 184 - June 1st 2024: [Apply Discount from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day184.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the | operator to filter the dataframe to customers that met the conditions for receiving a discount, then used the .count() function to count the number of customers that met the conditions
2. Day 185 - June 2nd 2024: [Electric Bike Replacement from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day185.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Filtered the dataframe to filter to eletric bikes that need to be replaced due to a high level of battery usage, then used the .count() function to count how many bikes need to be replaced
3. Day 186 - June 3rd 2024: [Average Revenue from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day186.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .groupby(), .mean(), and .reset_index() functions to find the average revenue and group the average revenue by store id. I then used the .sort_values() function to order by average revenue so the top earning stores showed at the top of the output table
4. Day 187 - June 4th 2024: [A/B Students from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day187.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the | operator to filter the dataframe to students who got an A or B for their final exam. Also used the .sort_values() function to order the output alphabetically
5. Day 188 - June 5th 2024: [Web Traffic from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day188.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .groupby() function to group the dataframe by visit date and used the .nunique() function to get the distinct count of visitors. Used the .sort_values() function to order the output by date sequentially
6. Day 189 - June 6th 2024: [Football Perfection from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day189.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the & symbol to filter the dataframe to football teams that had both a high number of points scored and a low number of penalties
7. Day 190 - June 7th 2024: [Animals from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day190.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the pd.concat() function to combine two datasets with common columns and remove any duplicates, used the .sort_values() function to order output alphabetically
8. Day 191 - June 8th 2024: [Sandwich Generation from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day191.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Performed the equivalent of a SQL CROSS JOIN in Python. Accomplished this by making a new column in each dataframe with the same name and value, then used pd.merge() to join the dataframes on the new common column. I then used .drop() to drop the common column and used the .sort_values() function to order the output alphabetically on bread name and meat name
9. Day 192 - June 9th 2024: [Unique from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day192.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .drop_duplicates() function to drop any duplicate customer ids from the dataframe, then used the .sort_values() function to order the output alphabetically by customer id
10. Day 193 - June 10th 2024: [Uber High and Low from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day193.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the | symbol to filter a dataframe on two separate conditions, used the .sort_values() function to order the output on income
11. Day 194 - June 11th 2024: [Fire Them! from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day194.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the & symbol to filter a dataframe on multiple conditions and wrote a formula to calculate the proportion of tasks that each employee has completed for the purpose of filtering. Used the .sort_values() function to order the output alphabetically on name
12. Day 195 - June 12th 2024: [Market Caps from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day195.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation to calculate market capitalization and used the ROUND() function to round output to 2 decimal places. Used the ORDER BY keyword to order the output by market capitalization descending
13. Day 196 - June 13th 2024: [Market Caps from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day196.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation to calculate market capitalization and used the .round() function to round output to 2 decimal places. Used the .sort_values() function to order the output by market capitalization descending
14. Day 197 - June 14th 2024: [Shrink-flation from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day197.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation to calculate the percent difference in item size and price, using the ROUND() function to round the percentages to the nearest whole number. Used a CASE statement to output "True" if an item decreased in size and increased in price, and "False" otherwise. Used the ORDER BY keyword to order the output alphabetically by item name
15. Day 198 - June 15th 2024: [Biggest Country Debts from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day198.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used a subquery in the WHERE clause to filter to where the year is equal to the MAX() year in the dataset, allowing the query to work in the future without any manual adjustments. Used the ORDER BY keyword to order by national debt descending and used the LIMIT keyword to grab only the top 3 countries with the highest debt. Used the ROUND() function to round the national debt to the nearest whole number in the output table
16. Day 199 - June 16th 2024: [Calculator Sales from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day199.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Started off by creating a CTE. In the CTE, I used the SUM() function and CASE statements to sum up the calculator sales for 2000 and 2023, storing both values in variables. In the outer query, I used the variables from the CTE to calculate the percent change in calculator sales between 2000 and 2023, using the ROUND() function to round the output to two decimal places
17. Day 200 - June 17th 2024: [Make it Cleaner! from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day200.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used multiple CASE statements to perform data cleaning on various columns. I first used a CASE statement to return NULL for product ids that were not greater than 0. I then used another CASE statement to return 0 for any values that were not greater than 0 in the quantity sold column. Finally, I used a CASE statement to plug in the dataset's average revenue for any NULL values in the revenue column. I used a small subquery within the CASE statement to SELECT the dataset's average revenue value
18. Day 201 - June 18th 2024: [Boss from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day201.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .merge() function to perform a self join and get employee names and boss names on the same row for the purpose of finding the boss for each employee. Performed a LEFT merge specifically to keep all employee data even if they don't have a boss. Used the .sort_values() function to get the output in alphabetical order
19. Day 202 - June 19th 2024: [Average Gaming Session from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day202.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Started by filtering the dataframe to gaming activities. I then used the .mean() function along with the .groupby() function to find average time spent on gaming grouped by user
20. Day 203 - June 20th 2024: [Kroger's Members from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day203.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation using the .count() function to calculate the percentage of Kroger shoppers that have a membership card, used the .round() function to round to two decimal places
21. Day 204 - June 21st 2024: [Big Pharma from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day204.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation to calculate the amount of money lost on different drugs. Used the .abs() function and .round() function to get the absolute value of money lost rounded to 1 decimal place, then filtered the dataframe to drugs that had a negative profit. I then returned the top three drugs that lost the most money by using the .head() function. There ended up being only two drugs that had lost money, so the final output table had two drugs
   
Fill in later (sick)

Fill in later (sick)

</details>
