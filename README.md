# **Welcome to My Practice Problems Repository!**
        
<br>           
      
**Table of Contents**
  
-   [Introduction](#introduction)
-   [List of Questions](#list-of-questions)
    - [December 2023](#december-2023)
    - [January 2024](#january-2024)
    - [February 2024](#february-2024)
    - [March 2024](#march-2024)
    - [April 2024](#april-2024)
    - [May 2024](#may-2024)
    - [June 2024](#june-2024)
    - [July 2024](#july-2024)
    - [August 2024](#august-2024)
    - [September 2024](#september-2024)
    - [October 2024](#october-2024)
    - [November 2024](#november-2024)
 
<br>

## Introduction

Starting on December 1st 2023, I'm going to do one practice problem per day! My goal with this repository is to:
- Further my coding skills to land a data analyst position
- Build up my GitHub profile

I'll continue doing these practice problems at least until I land a job as a data analyst, and possibly even after that! The practice questions will come from a variety of sources, such as:
- [DataLemur](https://datalemur.com/) 
- [Analyst Builder](https://www.analystbuilder.com/) 
- [HackerRank](https://www.hackerrank.com)
- [LeetCode](https://leetcode.com/)
- [PostgreSQL Exercises](https://pgexercises.com/)

Some of the practice problems will be in SQL and some will be in Python. Thank you for taking the time to view my practice problems repository :D

<br>


## List of Questions

### December 2023 

<details>

<summary>December 2023 Practice Problems</summary>

<br>

1. Day 1 - December 1st 2023: [Histogram of Tweets from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day1.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Subqueries, the DATE_PART function
2. Day 2 - December 2nd 2023: [Data Science Skills from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day2.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using the HAVING keyword to filter on aggregated data
3. Day 3 - December 3rd 2023: [Combine Two Tables from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day3.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the LEFT JOIN keyword to join the employee names on the employee locations, being sure to keep all employee names even if they don't exist in the location table. Used the ORDER BY keyword to order by first name alphabetically
4. Day 4 - December 4th 2023: [Page With No Likes from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day4.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: The IS NULL keyword, using a LEFT JOIN
5. Day 5 - December 5th 2023: [Big GDP from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day5.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the WHERE keyword to filter by GDP and used the ORDER BY keyword to order by the country name alphabetically
6. Day 6 - December 6th 2023: [Shopping Cart Conversions from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day6.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation to engineer a new feature, specifically the percentage of items that customers put in their cart that they actually bought. Used the ROUND() function to round to two decimal places and the ORDER BY keyword to order by customer id
7. Day 7 - December 7th 2023: [Most Orders from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day7.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used a subquery in the WHERE clause to filter to the customers with the MAX() number of orders
8. Day 8 - December 8th 2023: [Duplicate Emails from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day8.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the COUNT() function and the GROUP BY keyword to count the number of emails and group by email. I then used the HAVING keyword to filter on the aggregation and find instances where the email count was greater than 1, singling out users with duplicate emails. I used the ORDER BY keyword to order the output by email alphabetically
9. Day 9 - December 9th 2023: [Laptop vs. Mobile Viewership from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day9.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using a CASE statement and an aggregation function to engineer new features
10. Day 10 - December 10th 2023: [Unfinished Parts from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day10.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using the IS NULL keyword to filter to instances where a row value is missing
11. Day 11 - December 11th 2023: [Factorial Formula from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day11.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Utilizing a for loop for numeric calculations
12. Day 12 - December 12th 2023: [Movie Theater from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day12.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the WHERE and IN keywords together to filter on multiple values
13. Day 13 - December 13th 2023: [Heart Attack Risk from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day13.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the WHERE keyword, AND keyword, and inequalities to filter on multiple conditions that would put a patient at risk of a heart attack. Used the ORDER BY keyword to order by cholesterol descending since that's the most important indicator
14. Day 14 - December 14th 2023: [Wealthy Customers from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day14.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used COUNT DISTINCT to count the unique number of customers and used the WHERE keyword to filter to customers that spent at least 500 dollars in a single order
15. Day 15 - December 15th 2023: [Ice Cream Popularity from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day15.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used comparison operators and the WHERE keyword to compare two fields for the purpose of filtering. Used the ORDER BY keyword to order the output by ice cream flavor alphabetically
16. Day 16 - December 16th 2023: [Gamer Tags from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day16.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the LEFT function to select part of a string, the YEAR function to select part of a date, and the CONCAT function to combine them. Used the ORDER BY keyword to order by gamer tag
17. Day 17 - December 17th 2023: [Teams Power Users from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day17.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Aggregating with the COUNT() function, using the GROUP BY keyword to split the aggregation into different groups, using the DATE_PART function in combination with the WHERE keyword to filter by a specific month/year combo
18. Day 18 - December 18th 2023: [Cities With Completed Trades from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day18.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using the INNER JOIN keyword to combine two tables on a common column, aggregating with the COUNT() function, using the GROUP BY keyword to split the aggregation into different groups
19. Day 19 - December 19th 2023: [App Click-Through Rate (CTR) from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day19.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using a CASE statement within a calculation to engineer new a feature, using the ROUND() function to give output a uniform number of decimals, using the DATE_PART function and the WHERE keyword to filter to a specific year, using the GROUP BY keyword to group the aggregation by app
20. Day 20 - December 20th 2023: [Medium Sized Countries from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day20.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the BETWEEN keyword in combination with the WHERE keyword to filter to countries that have a population within the specified range. Used the ORDER BY keyword to order by population
21. Day 21 - December 21st 2023: [Million Dollar Store from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day21.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the ROUND() function to round output to two decimal places, used the HAVING keyword to filter on the average revenue, and used the GROUP BY keyword to group yearly revenue by store. Used the ORDER BY keyword to order by store id
22. Day 22 - December 22nd 2023: [Big Countries from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day22.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the OR keyword to filter to countries that met at least one of the specified conditions in the WHERE clause, used the ORDER BY keyword to order by country alphabetically
23. Day 23 - December 23rd 2023: [Low Quality YouTube Video from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day23.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation with pre-existing fields to engineer a new feature, the like percentage of a video. I then filtered on the like percentage by using the WHERE keyword and used the ORDER BY keyword to order the output by video id
24. Day 24 - December 24th 2023: [Cards Issued Difference from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day24.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using the MIN() and MAX() functions to perform calculations with aggregations, using the GROUP BY keyword to split aggregations up into groups
25. Day 25 - December 25th 2023: [Compressed Mean from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day25.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Performing calculations to engineer new features, using the ROUND() function to round output, using the CAST() function to convert values into different data types
26. Day 26 - December 26th 2023: [Average Post Hiatus from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day26.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using the DATE_PART function to deal with time series data, using the ::date syntax to quickly change the data type of a timestamp variable to date, using the HAVING keyword to filter on aggregated data
27. Day 27 - December 27th 2023: [Second Day Confirmation from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day27.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Performing an INNER JOIN to combine data from two different tables, using the PostgreSQL Interval function to add a specified time interval to a date value
28. Day 28 - December 28th 2023: [Device First Used from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day28.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the GROUP BY keyword and the MIN() function to find the earliest date a game was played grouped by device. Used the WHERE keyword to filter by game and the ORDER BY keyword to order by the date
29. Day 29 - December 29th 2023: [Tesla Models from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day29.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation to engineer a new feature, the profit made selling a car. Used the ORDER BY and LIMIT keywords to grab the record with the highest profit
30. Day 30 - December 30th 2023: [The Blunder from HackerRank](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day30.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using the CEIL() function to round output up to the nearest whole number, using the REPLACE() function to remove all zeros from a field for the purpose of fixing a miscalculation
31. Day 31 - December 31st 2023: [The PADS from HackerRank](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/december2023/day31.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Using the CONCAT() function to concatenate strings and variables in SQL

</details>


### January 2024

<details>

<summary>January 2024 Practice Problems</summary>

<br>

1. Day 32 - January 1st 2024: [Profit Margin from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day32.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation with existing fields to engineer a new feature, the profit margin for each product. Used the ROUND() keyword to format the numbers to a uniform number of decimals, and used the ORDER BY keyword to order by profit descending and product name ascending
2. Day 33 - January 2nd 2024: [On The Way Out from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day33.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the ORDER BY and LIMIT keywords together to only output the three oldest employees working at a company
3. Day 34 - January 3rd 2024: [Area Code from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day34.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the LEFT() function in combination with the WHERE keyword to filter to phone numbers that start with a specified area code
4. Day 35 - January 4th 2024: [Most Reviewed Restaurant from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day35.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the COUNT() function to count the number of comments and the AVG() function to find the average rating. Used the GROUP BY keyword to group by restaurant, used the ORDER BY keyword to order by comment count and average rating descending, and used the LIMIT keyword to only output the most reviewed restaurant
5. Day 36 - January 5th 2024: [Rotten Drama from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day36.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Calculated the difference between Rotten Tomato ratings and user ratings, then used the ABS() function to make all output positive. Used the ORDER BY and LIMIT keywords together to select the biggest rating difference
6. Day 37 - January 6th 2024: [Car Failure from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day37.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the AND keyword in combination with the WHERE keyword to filter on multiple conditions. Used the ORDER BY keyword to order by name alphabetically
7. Day 38 - January 7th 2024: [Best Classes from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day38.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the AVG() function to calculate the average grade, then used the GROUP BY keyword to group by class. Used the ORDER BY keyword to order by the average grade descending
8. Day 39 - January 8th 2024: [Homes Built from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day39.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the AND keyword in combination with the WHERE keyword and inequalities to filter on multiple conditions
9. Day 40 - January 9th 2024: [Higher Than 75 Marks from HackerRank](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day40.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using the RIGHT() function in combination with the the ORDER BY keyword to sort query output based off a specific part of a string
10. Day 41 - January 10th 2024: [Costco Rotisserie Loss from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day41.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the SUM() function to find the total revenue lost and used the ROUND() function to round to the nearest whole number
11. Day 42 - January 11th 2024: [Senior Citizen Discount from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day42.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Using the TIMESTAMPDIFF() function to find the difference between two dates, which I then used to filter to customers over a certain age
12. Day 43 - January 12th 2024: [Baseball Scouts from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day43.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used a CASE statement to make a skill level column that assigns players a level based on their batting average
13. Day 44 - January 13th 2024: [Men vs Women from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day44.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the AVG() function to calculate the average purchase price and the ROUND() function to round the output to 2 decimal places. Used the GROUP BY and ORDER BY keywords to group and order by gender
14. Day 45 - January 14th 2024: [Obesity from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day45.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the POWER() function and a formula to calculate BMI, used the ROUND() function to round the output to 2 decimal places. Then used the HAVING keyword to filter on BMI
15. Day 46 - January 15th 2024: [Pharmacy Analytics (Part 1) from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day46.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation to engineer a new feature, used ORDER BY in combination with LIMIT to output only the top three records
16. Day 47 - January 16th 2024: [Pharmacy Analytics (Part 2) from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day47.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used a combination of aggregations, filtering, grouping, and ordering to find out which drug manufacturers give CVS the most losses, along with the number of drugs produced by the manufacturer that are associated with losses. Also used the ABS() function to get the total losses as a positive number
17. Day 48 - January 17th 2024: [Pharmacy Analytics (Part 3) from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day48.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Calculated the total sales for CVS drugs grouped by manufacturers, used the CONCAT() and ROUND() function to give the output a uniform and easily readable format
18. Day 49 - January 18th 2024: [Sandwich Generation from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day49.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the CROSS JOIN keyword to combine each row of one table with each row of a second table, which allowed me to find each possible sandwich combination with the provided ingredients
19. Day 50 - January 19th 2024: [Separation from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day50.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: In this question, user ID's and user first names were accidentally combined into one string. I used the LEFT() function to make a separate field for the ID's, and used the SUBSTRING() function to make a separate field for the names
20. Day 51 - January 20th 2024: [Unique from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day51.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using the DISTINCT keyword to only grab unique values from a column, using the ORDER BY keyword to sort the output
21. Day 52 - January 21st 2024: [Food Divides Us from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day52.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the GROUP BY keyword, ORDER BY keyword, and LIMIT keyword to group fast food spending by region, order the output based on total fast food spending per region, and grab the top spending region
22. Day 53 - January 22nd 2024: [2022 Orders from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day53.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the INNER JOIN keyword to join two datasets on common columns, filtered by multiple conditions in the WHERE clause, used the YEAR() function to extract the year from a date for filtering purposes
23. Day 54 - January 23rd 2024: [Bad Bonuses from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day54.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used a subquery in the WHERE clause to filter to instances where a value in one table didn't exist in a second table, identifying employees that didn't receive bonuses
24. Day 55 - January 24th 2024: [Pepperoni-flation from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day55.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation in the SELECT statement combined with using the WHERE keyword to calculate how much money a pizza restaurant would save by putting less pepperoni on their pizzas
25. Day 56 - January 25th 2024: [Kroger's Members from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day56.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation in the SELECT statement to calculate the percentage of Kroger shoppers that have a membership card, used the ROUND() function to round to two decimal places
26. Day 57 - January 26th 2024: [Bike Price from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day57.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation in the SELECT statement to calculate the average sale price for bikes, using the IS NOT NULL keyword in the WHERE clause to exclude bikes that were donated so that it doesn't throw off the calculation, used the ROUND() function to round to two decimal places
27. Day 58 - January 27th 2024: [Water Pollution from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day58.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the GROUP BY keyword to group average pollution concentration by pollutant, used the HAVING keyword to filter on the aggregation, used the ROUND() function to round to two decimal places
28. Day 59 - January 28th 2024: [Company Wide Increase from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day59.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used a CASE statement to engineer a new feature that determined the new salary for each employee depending on the pay level they were on
29. Day 60 - January 29th 2024: [LinkedIn Famous from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day60.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation to determine the popularity score of LinkedIn posts based off their impressions and interactions, filtered and sorted by the popularity score to get posts only of a specified popularity level
30. Day 61 - January 30th 2024: [Intern Problems from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day61.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used a CASE statement to edit certain values in a column, making the column have uniform formatting throughout
31. Day 62 - January 31st 2024: [Big Pharma from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/january2024/day62.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the ABS() function to get the absolute value of money lost, then filtered to drugs that had a negative profit and returned the three drugs that lost the most money - there ended up being only two drugs that had lost money, so the final output table had two drugs

</details>


### February 2024

<details>

<summary>February 2024 Practice Problems</summary>

<br>

1. Day 63 - February 1st 2024: [Buying Less from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day63.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the GROUP BY keyword to group all orders by customer id, then used the HAVING keyword to filter on total amount of money spent and total number of orders made with the purpose of targeting advertising to customers that don't spend as much
2. Day 64 - February 2nd 2024: [Greenhouse Gases from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day64.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed an aggregation to calculate total carbon emissions and used the ROUND function to make the output uniform, used the GROUP BY keyword to group the total emissions by country, then used the ORDER BY and LIMIT keywords to find the country with the most carbon emissions
3. Day 65 - February 3rd 2024: [Richie Rich from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day65.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the GROUP BY keyword to group total profit buy company, used the HAVING keyword to filter on the total profit aggregation, used the DATE_SUB function to filter to profit within a few years of a specified date
4. Day 66 - February 4th 2024: [Crew Overspending from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day66.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed an aggregation to calculate total spending, used a CASE statement to code different outputs based on the amount of spending, used the GROUP BY keyword to group the spending by employee
5. Day 67 - February 5th 2024: [Perfect Data Analyst from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day67.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used a combination of the AND, OR, and IS NOT NULL operators in the WHERE clause to identify candidates that met specific qualifications
6. Day 68 - February 6th 2024: [Gmail Users from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day68.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the SQL LIKE keyword and the wildcard character % to select all users who use Gmail as their email provider, AKA all emails that end in @gmail.com
7. Day 69 - February 7th 2024: [Average Gaming Session from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day69.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the AVERAGE function along with the WHERE keyword to find average time spent on gaming, used the GROUP BY keyword to group the results by user id
8. Day 70 - February 8th 2024: [Uber High and Low from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day70.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the OR keyword in combination with the WHERE keyword to filter on two separate conditions, used the ORDER BY keyword to order the output on income
9. Day 71 - February 9th 2024: [A/B Students from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day71.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the OR keyword in combination with the WHERE keyword to filter to students who got an A or B for their final exam, used the ORDER BY keyword to order the output alphabetically
10. Day 72 - February 10th 2024: [Football Perfection from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day72.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the AND keyword in combination with the WHERE keyword to filter to football teams that had both a high number of points scored and a low number of penalties
11. Day 73 - February 11th 2024: [Animals from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day73.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the UNION keyword to combine two datasets with common columns and remove any duplicates, used the ORDER BY keyword to order output alphabetically
12. Day 74 - February 12th 2024: [Electric Bike Replacement from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day74.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the WHERE keyword to filter to electric bikes that need to be replaced due to a high level of battery usage, then used the COUNT() function to count how many bikes need to be replaced
13. Day 75 - February 13th 2024: [Chocolate from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day75.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the WHERE keyword in combination with the LIKE keyword to select all items that have the word chocolate anywhere in their name
14. Day 76 - February 14th 2024: [Average Revenue from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day76.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the AVG() function to find average revenue, used the GROUP BY keyword to group the average revenue by store, then used the ORDER BY keyword to order by average revenue so the top earning stores showed at the top of the output table
15. Day 77 - February 15th 2024: [Apply Discount from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day77.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the WHERE keyword in combination with the OR keyword to filter to customers that met the conditions for receiving a discount, then used the COUNT() function to count the number of customers that met the conditions
16. Day 78 - February 16th 2024: [Web Traffic from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day78.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the COUNT(DISTINCT) function to count the number of unique visitors on a website, used the GROUP BY keyword to group the visitors by date
17. Day 79 - February 17th 2024: [Product Launch from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day79.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used CASE statements and the COUNT() function together to count the number of product launches in 2022 and 2023, then performed subtraction to find the difference in the number of product launches between the two years. Used the GROUP BY keyword to group the difference by company, and used the ORDER BY keyword to order the output alphabetically
18. Day 80 - February 18th 2024: [Multi-Level Marketing from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day80.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the SUM() aggregation to add up total profits, used the MONTH() function to extract the month from a date field, then used the GROUP BY keyword to group the profits by month. Used the HAVING keyword to filter to the first half of the year and to months where the sum of the profit was greater than zero, then used the ORDER BY keyword to order by profit
19. Day 81 - February 19th 2024: [Football Attendance from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day81.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the SUM() aggregation to add up total season attendance, used the GROUP BY keyword to group the attendance by season, then used ORDER BY and LIMIT together to only output the season with the top attendance
20. Day 82 - February 20th 2024: [Tech Layoffs from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day82.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation to find the percentage of the company that got laid off from their job and used the ROUND() function to clean up the output into a uniform number of decimals. Used the GROUP BY keyword to get the percentage of the company laid off for each company in the dataset
21. Day 83 - February 21st 2024: [Cloud Storage Fees from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day83.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation to see which users had gone over their alloted 200gb of cloud storage so that they could pay a fee, used the ABS() function to get the result in absolute value rather than negative
22. Day 84 - February 22nd 2024: [Must Buy it All from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day84.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the HAVING keyword in combination with the COUNT(DISTINCT) keyword to filter to customers that had bought all of a company's products, used the GROUP BY keyword to group the product count by each customer
23. Day 85 - February 23rd 2024: [Computer Replacement from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day85.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the MySQL DATE_SUB() function in combination with the WHERE keyword to filter to computers that were bought over five years ago so they can be replaced
24. Day 86 - February 24th 2024: [SuperCoolElectronicsStore.com from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day86.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the LIKE keyword along with the wildcard character % to find laptop names that mentioned SSD storage or HDD storage, then used a CASE statement to engineer a new column that holds the storage type
25. Day 87 - February 25th 2024: [Media Addicts from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day87.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed an INNER JOIN to combine two datasets with information about how much time a user spent on social media and the name of each user. Then used the WHERE keyword in combination with a small subquery to filter to users that spent more time on social media than average, returning the first name of users with above average usage in alphabetical order with the help of the ORDER BY keyword
26. Day 88 - February 26th 2024: [Ranking Students from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day88.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the DENSE_RANK() function to assign students a rank number based on their grade, assigning students with the same grade value the same rank number. Used the ORDER BY keyword to order by both ranks descending and names alphabetically, that way students with the same ranks still have a defined order
27. Day 89 - February 27th 2024: [TMI (Too Much Information) from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day89.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the SUBSTRING_INDEX() function to split a field with customer's first and last names into two based on the position of the space, then returned the first half of the string to only select first names
28. Day 90 - February 28th 2024: [Movie-aholic from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day90.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the INNER JOIN keyword to join two tables with customer data and data on the movies they watched. Used the ORDER BY keyword in combination with the COUNT() keyword to order output by the number of movies descending, using the GROUP BY keyword to group the number of movies by each customer. Then used the LIMIT keyword to only return the name of the customer that had watched the most movies
29. Day 91 - February 29th 2024: [Employee Turnover from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/february2024/day91.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used a CASE statement in combination with the YEAR() function and COUNT() function to count instances where employees left the company in 2022. Then divided by the total number of employees and multiplied by 100 to calculate the employee turnover rate for the year of 2022

</details>


### March 2024

<details>

<summary>March 2024 Practice Problems</summary>

<br>

1. Day 92 - March 1st 2024: [Full Time Jobs from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day92.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Combined two datasets on job data using the UNION keyword. Then used the union as a subquery so I could count the number of rows in the combined table. Used the WHERE and HAVING keyword together to filter to instances where an employee had two full-time jobs, then used the GROUP BY keyword to group the instances by employee name
2. Day 93 - March 2nd 2024: [Boss from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day93.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed a self join to get employee names and boss names on the same row for the purpose of finding the boss for each employee, a LEFT JOIN specifically to keep all employee data even if they don't have a boss. Used the ORDER BY keyword to get the output in alphabetical order
3. Day 94 - March 3rd 2024: [Direct Reports from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day94.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed a self join to tie the employee ids to the manager ids. Used the LIKE keyword and the wildcard character % in the WHERE clause to filter to positions that had the word manager anywhere in its name. Then performed a COUNT() on the number of times each manager id showed up and used the GROUP BY keyword to group by manager id and position, finding the number of direct reports for each manager
4. Day 95 - March 4th 2024: [Amazon Returns from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day95.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the GROUP BY keyword to group by order id - each product bought had its own row even if they were part of the same order, so this was necessary to look at the order total as a whole rather than by each item. Then used the HAVING keyword in combination with the SUM() function to filter to instances where the potential profit of the entire order was less than the estimated return price of the entire order
5. Day 96 - March 5th 2024: [Employee Raise from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day96.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Started by writing a query that used the MIN() function to select the lowest salary, then used the GROUP BY keyword to get the lowest salary by department. Used this query as a subquery for a JOIN, joining the query with the employee data on the department and salary fields. Then performed a calculation to determine the new salaries for the lowest paid employee in each department, using the ORDER BY keyword to sort the output by largest new salary to smallest new salary
6. Day 97 - March 6th 2024: [Who Made Quota? from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day97.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Started off by using the INNER JOIN keyword to join data on sales and assigned sales quotas. Then used a CASE statement to engineer a new column to determine if each salesperson met their quota
7. Day 98 - March 7th 2024: [Duplicate Job Listings from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day98.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Wrote a query that used the COUNT() function to count the number of jobs, then used the GROUP BY keyword to group by company id, job title, and job description to find instances where there were duplicate job listings. Used that query as a subquery to count the number of companies WHERE they have duplicate listings
8. Day 99 - March 8th 2024: [Movie-aholic (Joins) from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day99.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: This is an alternate version of the Movie-aholic practice problem I completed on Day 90 - this version of the problem focuses on joining multiple tables. I performed an INNER JOIN twice to get data from three different tables into one output table, then outputted the name of the customer, the movie they watched, and what date they watched it on
9. Day 100 - March 9th 2024: [Running Total from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day100.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: In this problem I used a window function to find a running total of points for each gender over multiple days. I found the SUM() of the points, used PARTITION BY to group on the gender, then used the ORDER BY keyword within the window function to order by the date. I then also ordered by the points within the window function to find the running total of points
10. Day 101 - March 10th 2024: [Breaking Out Column from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day101.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the SUBSTRING_INDEX() function, including nested SUBSTRING_INDEX() functions, to break out an address field into separate street, city, state, and zip code columns. Used the TRIM() function to clear up any white space inconsistencies
11. Day 102 - March 11th 2024: [Contact Information from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day102.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Performed an INNER JOIN to connect customer data to their contact data. Used a CASE statement to find instances where the user's email was NULL in the contact table so we could create an email for them. It was specified that the user's email should be their first name combined with their last name with a gmail domain in all lowercase, so I used the CONCAT() function, the LOWER() function, and customer data to create email addresses for anyone missing one
12. Day 103 - March 12th 2024: [Art Ranking from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day103.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the RANK() window function to assign ranks to artists based on their total score across three judges. The SUM() function was used to calculate each artists' total score, then the total score was used in the window function to order the output descending, ensuring that the artists with the highest points were ranked first
13. Day 104 - March 13th 2024: [Fire Them! from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day104.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Using the AND keyword in the WHERE clause to filter on multiple conditions and writing a formula to calculate the percentage of tasks that each employee has completed
14. Day 105 - March 14th 2024: [Help Desk Manager from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day105.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used a CASE() statement in combination with the SUM() function to add up the number of calls that had been resolved, then used the COUNT() function to divide by the total number of calls and multiplied by 100 to get the result as a percentage. Lastly, I used the GROUP BY keyword and grouped by employee name to view the percentage of calls each employee resolved over the total number of calls they've taken
15. Day 106 - March 15th 2024: [Unions from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day106.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the UNION ALL keyword to combine medication and dosage information from two tables, keeping duplicates. Used the ORDER BY keyword to order the output alphabetically
16. Day 107 - March 16th 2024: [Salary By Department from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day107.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the AVG() function to find the average salary, then used PARTITION BY within a window function to compare each person's salary to the AVG() salary of their department. I then ordered by department alphabetically and salary descending to order each department from their highest earners to their lowest earners
17. Day 108 - March 17th 2024: [Temperature Fluctuations from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day108.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the LAG() window function to get the previous date's temperature next to the current date's temperature in the output table. Then used that query as a subquery and selected the dates from that query only when the current date's temperature was greater than the previous date's temperature
18. Day 109 - March 18th 2024: [Kelly's 3rd Purchase from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day109.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the ROW_NUMBER() window function, then used PARTITION BY to split it up by customer id and used ORDER BY to order it by transaction id ascending, making sure each customer's purchases were in sequential order. That query now assigned a row number to each purchase a customer made, so I used it as a subquery and had the outer query only grab the third order from each customer, performing a calculation to apply a discount to each third order
19. Day 110 - March 19th 2024: [Right Twix vs Left Twix from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day110.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Performed a calculation to see what percentage of consumers voted for right twix or left twix. Divided each side by the total number of votes and multiplied by 100 to get it as a percentage, then used the ROUND() function to round the output to 2 decimal places
20. Day 111 - March 20th 2024: [Good Dog Bad Owner from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day111.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used a CASE statement to see if dog owners had walked their dogs enough to be considered a good owner. If they had multiple dogs, they must have walked both enough to be considered a good owner. Achieved this by finding the SUM() of all walks grouped by owner name and dog name to see how much each owner had walked each dog over the week. Then used that query as a subquery to check the MIN() of total walks - that way owners who had walked one of their dogs enough but not their other dogs enough would be labelled as bad owners by the CASE statement
21. Day 112 - March 21st 2024: [Highest Grade from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day112.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the ROW_NUMBER() window function in combination with the PARTITION BY keyword to group by student and the ORDER BY keyword to order by grade descending and class id ascending. This allowed me to get the top grades for each student as row number 1, and when a tie in grades happened it would be based on the lowest class id. I then used that query as a subquery to filter to instances where the row number was 1, allowing me to select the top grade and its corresponding subject and class id for each student
22. Day 113 - March 22nd 2024: [2nd Highest from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day113.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Started by using the INNER JOIN keyword to join the departments and employees tables on department id. I then used the ROW_NUMBER() window function in combination with the PARTITION BY keyword to group by department and the ORDER BY keyword to order by salary descending. I used that query as a subquery and filtered to instances where the row number was 2, allowing me to select the second highest earner in each department
23. Day 114 - March 23rd 2024: [Unfair Taxation from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day114.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used a window function in combination with the PARTITION BY keyword to SUM() up the total salary for each company, then used the query as a subquery. In the outer query I wrote a case statement to tax employee salaries depending on the total salary for their respective companies
24. Day 115 - March 24th 2024: [Investment Properties from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day115.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Started by calculating profit on home sales by subtracting the purchase price from the sale price. I then used that query as a subquery and used a window function to get a rolling total for the SUM() of profit
25. Day 116 - March 25th 2024: [Hotel Guests from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day116.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the COUNT() function to count the number of check outs. Used the WHERE keyword in combination with the MySQL TIME() function to filter to checkouts that happened after 10am, the checkout time. The final query counted the number of guests that checked out late
26. Day 117 - March 26th 2024: [Approved Transactions from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day117.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the MONTH() function to extract the month from a date field. Used multiple CASE() statements to find the number of approved transactions and the total amount of money approved as well as the number of denied transactions and the total amount of money denied. Used the GROUP BY keyword to group by month and country so that each month from each country had its own row
27. Day 118 - March 27th 2024: [Help Requests from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day118.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used multiple CASE statements to count the number of completed requests, count the number of incomplete requests, and calculate the percentage of completed requests. I then used the GROUP BY keyword to group by request type, allowing us to break down the counts and percentage within each type of request
28. Day 119 - March 28th 2024: [Inactive Accounts from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day119.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Started by writing a query that selects the user id of users that had been active recently. Used that as a subquery in the WHERE clause to find user ids that were not in the list of active users. Used the GROUP BY keyword to group by user id so that each inactive user id only showed up once in the output table
29. Day 120 - March 29th 2024: [Customer Transactions from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day120.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Wrote a query that uses the SUM() function to calculate the total money spent and the GROUP BY function to group by customer id. Then used the RANK() window function to rank each customer by their spending and used the ORDER BY keyword to order on the total sales, the rank number, and the customer id. I then used that entire query as a subquery and filtered to rows where the rank number was 1, 2, or 3
30. Day 121 - March 30th 2024: [JANINE!! from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day121.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used regular expression, more specifically the REGEXP_REPLACE() function, to remove any non-alphanumeric characters from the product name. Then used that query as a subquery so I could fix the capitalization of the fixed product names. I used the MySQL UCASE() function in combination with the LEFT() function to capitalize the first letter, used the LCASE() function in combination with the SUBSTRING() function to make the rest of the word after the first letter lowercase, then used the CONCAT() function to combine them into the full product name
31. Day 122 - March 31st 2024: [Chef Malpractice from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/march2024/day122.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the SUM() function in combination with the CASE() function to add up the number of orders that were returned to the kitchen, then used the GROUP BY keyword to group by chef. Afterwards, I used the RANK() window function and nested it with the CASE() function to order by the number of returned orders descending. I then used that entire query as a subquery and used the WHERE keyword to filter the rank number to 1, allowing me to select the chef with the most food sent back to the kitchen
    
</details>


### April 2024

<details>

<summary>April 2024 Practice Problems</summary>

<br>

1. Day 123 - April 1st 2024: [Twitter Addiction from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day123.md)
    - Languages Used: SQL
    - Question Difficulty: Very Hard
    - Concepts Covered: Used the TIMESTAMPDIFF() and LAG() window function together to find the time between posts for Twitter users. I used that query as a subquery and utilized the AVG() function to find the average amount of time between posts for each user
2. Day 124 - April 2nd 2024: [Domain Knowledge from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day124.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the SUBSTRING_INDEX function twice, first to split on the @ symbol and second to split on the . symbol, which allowed me to select only the domain for each email address. Then I used that query as a subquery, and in the outer query I used the COUNT() function and the GROUP BY keyword to see how many times each domain appeared in the dataset
3. Day 125 - April 3rd 2024: [Returning Customers from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day125.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the MySQL DATEDIFF() function and the LAG() window function together to find out how long customers took to place a new order relative to their previous order. I used that query as a subquery and in the outer query I used the WHERE keyword to filter to where the number of days between purchases was less than or equal to 5, then used the GROUP BY keyword to group by user id
4. Day 126 - April 4th 2024: [Basketball Greatness from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day126.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the DENSE_RANK() window function to rank basketball players based on total points scored. The question specified that in case of a tie the next rank should be the next consecutive integer, which is how I knew to use DENSE_RANK() over RANK()
5. Day 127 - April 5th 2024: [Merry Facebook from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day127.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the RANK() window function to rank Facebook actions (such as comments, likes, etc.) based on how many times they were performed. Used the WHERE keyword to filter the date to Christmas day to look at only Christmas actions and used the GROUP BY keyword to group the count of actions by each action type
6. Day 128 - April 6th 2024: [Name Format from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day128.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used a combination of the LEFT() function, SUBSTRING() function, UPPER() function, and LOWER() function to fix the capitalization of name fields and put them in Proper Case, with the first letter capitalized and everything else lowercase. I then used the CONCAT() function to create a field that holds the full name in Proper Case
7. Day 129 - April 7th 2024: [Job Search from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day129.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used a combination of the AND keyword, the OR keyword, the LIKE keyword, the wildcard character %, and the SUBSTRING_INDEX() function in the WHERE clause to perform complex filtering on job postings. I filtered on job title, required skills, and salary
8. Day 130 - April 8th 2024: [Cake vs Pie from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day130.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used CASE statements to add up the number of cakes and pies sold, then used the GROUP BY keyword to group by date and view how many were sold each day. I then made another CASE statement to output which dessert was more popular for each date and calculated the difference in the number of products sold
9. Day 131 - April 9th 2024: [Internet Outages from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day131.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the STR_TO_DATE function to convert the data type of the date fields from strings to dates. Then used the AVG() and TIMESTAMPDIFF() function to calculate the average number of minutes that an internet outage lasts, using the GROUP BY keyword to group by each ISP. I also used a CASE statement to add up cases where the end date of the outage IS NULL, meaning that the outage is still ongoing
10. Day 132 - April 10th 2024: [Lyft Bonuses from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day132.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used a CASE statement to calculate bonuses for each Lyft driver depending on the number of rides they completed - $100 for 100 rides, $500 for 500 rides, $1000 for 1000 rides, and an extra $1000 for each 1,000 rides afterwards. I used the FLOOR() function within a calculation to round the rides to the lowest thousand - so a driver with 7,500 rides would be counted as having 7000 rides to calculate the bonus for the last thousand they reached
11. Day 133 - April 11th 2024: [Price Check from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day133.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used the SELECT, GROUP BY, and WHERE keywords to select the MAX() of the date for each product before or on a certain date, grouped by product id. Then used that query as a subquery and selected the product id and price and did an INNER JOIN on the subquery output table and the base table. I joined on product id and the date from the main table being equal to the MAX() date from the subquery table, finding the most recent product price
12. Day 134 - April 12th 2024: [Consecutive Visits from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day134.md)
    - Languages Used: SQL
    - Question Difficulty: Very Hard
    - Concepts Covered: Started off by creating a CTE. Within the CTE, I joined the two datasets on customer id, selected all the columns, and used the DATEDIFF() function to find the difference between the visit date and the last visit date. The last visit date was calculated using the LAG() window function on visit date, using the PARTITION BY keyword to group by customer id and the ORDER BY keyword to order on the visit date. I then made a query that selected everything from that CTE, along with a CASE() statement that used the SUM() function to add up cases where the days between visits were equal to 1, meaning the visit was consecutive. I also had to add 1 to the CASE statement's results to count the first visit. With all that done, I used that query as a subquery to grab the MAX() of the consecutive visits
13. Day 135 - April 13th 2024: [Biggest Spenders from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day135.md)
    - Languages Used: SQL
    - Question Difficulty: Very Hard
    - Concepts Covered: Started off by creating a CTE to join the two datasets on customer id, selected all the columns, and used the MONTH() function to extract the month from the purchase date column. I then made a query that selected everything from that CTE, while also calculating the total spending and row numbers. The total spending was calculated by using the SUM() function and using the GROUP BY keyword to group by month and customer. The row number was calculated with the ROW_NUMBER() window function, using the PARTITION BY and ORDER BY keywords to assign the highest spenders per month to row number 1. I then used that query as a subquery to grab the records WHERE the row number was equal to 1, selecting only the biggest spenders for each month
14. Day 136 - April 14th 2024: [NASCAR Times from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day136.md)
    - Languages Used: SQL
    - Question Difficulty: Very Hard
    - Concepts Covered: Started off by creating a CTE that used the DENSE_RANK() window function to give a ranking number to the laps based on their times. I then made a query that selects rank numbers 1, 2, 3, 21, 22, and 23 to filter to the three fastest and three slowest times. I used the GROUP BY keyword to group by lap time, which got rid of any duplicates. I then used a CASE statement to label the laps the fastest laps or slowest laps based on their rank number. I then used that query as a subquery and used the RANK() window function to PARTITION BY label and rank the fastest and slowest laps separately. I needed to order the slowest laps descending and the fastest laps ascending, so I used a CASE statement to rank the lap times differently based on their label. Finally, I used the ORDER BY keyword to order by label descending and ranking ascending to get the desired format for the output
15. Day 137 - April 15th 2024: [Complex Address from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day137.md)
    - Languages Used: SQL
    - Question Difficulty: Very Hard
    - Concepts Covered: Used the SUBSTRING_INDEX() function to convert an address stored in one field to separate fields for the street, city, state, and postal code. I used a CASE statement for the street address to ensure that unnecessary information such as the unit or suite numbers are removed. I also used the TRIM() function to remove any extra whitespace from the data, ensuring consistent formatting
16. Day 138 - April 16th 2024: [Uber Cancellation Rates from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day138.md)
    - Languages Used: SQL
    - Question Difficulty: Very Hard
    - Concepts Covered: Started off by creating a CTE to filter and join the data. I had to use the JOIN keyword twice, once to join the client ids with the user ids and once to join the driver ids with the user ids. I also made sure to filter to only unbanned users and to the dates specified in the question. I selected from that CTE for my query, where I added up cancelled rides, divided by all rides, and multiplied by 100 to calculate the cancellation rate. To calculate the cancelled rides I used the SUM() function and a CASE statement together to add up the rides where the status was not equal to completed, and I just used the COUNT() function on a field to get the total rides. I ended off the query by using the ROUND() function to round the percentage to 2 decimals and used the GROUP BY keyword to group by the date, getting a separate percentage for each date in the date range
17. Day 139 - April 17th 2024: [Employee Hierarchy from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day139.md)
    - Languages Used: SQL
    - Question Difficulty: Very Hard
    - Concepts Covered: I used a recursive CTE to complete this problem. I grabbed the employee id from the hierarchy table and made a field named level with a numeric value of 1, then used the WHERE keyword to filter to instances where the supervisor id IS NULL. The very top employees don't have supervisors, so that assigned those employees to level 1. I then used the UNION ALL keyword, and in the next query I grabbed employee id again and added 1 to the level. I joined the hierarchy table and the employeehierarchy CTE where the supervisor id from the hierarchy table was equal to the user id from the employeehierarchy CTE, which assigned each employee a level number based on who their supervisor is - people with no supervisor were a level 1 employee, people with a level 1 supervisor were level 2 employees, and so on. With that recursive CTE complete, I made a query to grab the employee id and level field from the completed employeehierarchy CTE and used the ORDER BY keyword to order by employee id
18. Day 140 - April 18th 2024: [Inflation from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day140.md)
    - Languages Used: SQL
    - Question Difficulty: Very Hard
    - Concepts Covered: Started by creating a CTE where I selected the country, the consumer price index field to grab the current inflation rate, and the previous consumer price index to grab the previous inflation rate. The previous inflation rate was calculated with the LAG() window function, using the PARTITION BY and ORDER BY keywords to group by country and order by year. I then used that CTE to find the average inflation rate. The average inflation rate was calculated by subtracting the previous inflation rate from the current inflation rate, dividing by the previous inflation rate, multiplying by 100, then using the AVG() function to average it all. I then used the RANK() window function to rank the countries based on their average inflation rate and ordered by the rank number
19. Day 141 - April 19th 2024: [Sending vs. Opening Snaps from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day141.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Created a CTE that used the INNER JOIN keyword to join the activities and age breakdown tables on the user id. In the CTE I also used CASE statements to add up time spent based on whether the activity type was sending Snapchats or opening Snapchats, then used the GROUP BY keyword to group the time spent on each activity by age group. I then used that CTE to perform a calculation that finds how much time was being spent on the sending vs. opening rates as a percentage total of time spent on both activities. I finished up the query by using the ROUND() function to round the percentages to two decimal places
20. Day 142 - April 20th 2024: [Odd and Even Measurements from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day142.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Created a CTE that grabbed the measurement values, the DATE_TRUNC() of the date field aggregated to day, and the ROW_NUMBER() window function with a PARTITION BY the day. From that CTE I selected the measurement day, then used CASE statements to SUM() the measurement values based on whether or not the row number was even or odd. I tested this by using the modulo (%) operator on the row number, as any even number modulo 2 is 0 and odd numbers result in a 1. I finished up the query with the GROUP BY keyword to group by the day, resulting in the total even and odd measurements for each day in the dataset.
21. Day 143 - April 21st 2024: [User's Third Transaction from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day143.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the ROW_NUMBER() window function with a PARTITION BY user id, using the ORDER BY keyword to order by the transaction date and assign a row number to each user's transactions. I then used that query as a subquery and used the WHERE keyword to filter where the row number was equal to 3, grabbing each user's third order
22. Day 144 - April 22nd 2024: [Tweets' Rolling Averages from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day144.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the AVG() window function with a PARTITION BY user id, using the ORDER BY keyword to order by the tweet date ascending, resulting in a rolling average. I then used the ROWS BETWEEN keyword to only average the two preceding rows and the current row, making a rolling 3-day average. I finished off by using the ROUND() function to round the output to 2 decimal places
23. Day 145 - April 23rd 2024: [Histogram of Users and Purchases from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day145.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the RANK() window function with a PARTITION BY user id, using the ORDER BY keyword to order by the transaction date descending, resulting in the most recent transaction date for each user being assigned a rank number of 1. I then used the COUNT() function on the product id column to count the number of purchases since some customers made more than one purchase in a day. I used the WHERE keyword to filter the rank number to 1 and the GROUP BY keyword to group by transaction date and user id
23. Day 145 - April 23rd 2024: [Histogram of Users and Purchases from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day145.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the RANK() window function with a PARTITION BY user id, using the ORDER BY keyword to order by the transaction date descending, resulting in the most recent transaction date for each user being assigned a rank number of 1. I then used the COUNT() function on the product id column to count the number of purchases since some customers made more than one purchase in a day. I used the WHERE keyword to filter the rank number to 1 and the GROUP BY keyword to group by transaction date and user id
24. Day 146 - April 24th 2024: [Highest-Grossing Items from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day146.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I started by creating a CTE. In the CTE, I used the SUM() function to find the total amount of money spent, then used the RANK() window function with a PARTITION BY item category, using the ORDER BY keyword to order by the SUM() of money spent descending. I used the DATE_PART function in the WHERE clause to filter to purchases that took place in 2022, then used the GROUP BY keyword to group by category and product. This put the top two products based on money spent for each category in 2022 at rank number 1 and 2. I then selected the category, product, and total money spent from the CTE and used the WHERE keyword to filter to the rank being 1 or 2
25. Day 147 - April 25th 2024: [Top 5 Artists from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day147.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I started by creating a CTE. In the CTE I used the INNER JOIN keyword twice, once to join the artists table with the songs table, and once to join the songs table with the global song rank table. I selected the artist name and used the DENSE_RANK() window function in combination with the ORDER BY keyword to give artists a rank based on the COUNT() of song id. I also used the WHERE keyword to filter to instances where the global song rank was 10 or lower, which means I only counted songs that reached the top 10 in global charts for each artist. I used the GROUP BY keyword to group by artist so that each artist only showed up once in the output table. With the CTE completed, I selected the artist name and artist rank from it, then used the WHERE keyword to filter the artist rank to 1, 2, 3, 4, and 5 to find the top 5 artists in terms of top 10 hits
26. Day 148 - April 26th 2024: [Patient Support Analysis (Part 1) from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day148.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: I used the SELECT keyword to grab the policy holder's id and COUNT() the case id field. I used the GROUP BY keyword to group by policy holder id and used the HAVING keyword to filter to instances where the COUNT() of the case id field was greater than or equal to 3. I then used that query as a subquery, and in the outer query I used the COUNT() function to count the number of policy holder id's. The output represented how many policy holders in the dataset made three or more calls about their health care needs
27. Day 149 - April 27th 2024: [Patient Support Analysis (Part 2) from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day149.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: The calls category column is either NULL or has a value of 'n/a' when the call is uncategorized, so I made a CASE statement in combination with the SUM() function to count the instances where a call was uncategorized. I then used the COUNT() function to tally the total number of calls. I used that query as a subquery, and in the outer query I calculated the percentage of uncategorized calls in the table, using the ROUND() function to round the output to 1 decimal place
28. Day 150 - April 28th 2024: [Signup Activation Rate from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day150.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Started by creating a CTE and joining the emails and texts table. I did a RIGHT JOIN to keep all records in the text table, that way when I used the COUNT() function it counted all the text data even if the user wasn't in the emails table. I also used a CASE statement with the SUM() function to tally the number of users that activated their account via text. With that CTE done, I divided the confirmed accounts by the total accounts and used the ROUND() function to round to 2 decimal places
29. Day 151 - April 29th 2024: [Compressed Mode from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day151.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Started by creating a CTE where I selected the item count, order occurrences, and used the RANK() window function to assign a rank to each row based on the order occurrences descending. With that CTE completed, I selected the item count from the CTE, then filtered to where the rank was equal to 1 to find the most popular item counts. I used the ORDER BY keyword to order by the item count ascending since two item counts tied for first place
30. Day 152 - April 30th 2024: [Card Launch Success from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/april2024/day152.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Started by creating a CTE and using the RANK() window function with a PARTITION BY the card name and an ORDER BY the issue year ascending and the issue month ascending. This assigned every initial launch of a card a rank of 1, so I wrote a query that selected the card name and issued cards amount where the rank number was equal to 1, showing how many cards were issued in the first month for each credit card type

</details>


### May 2024

<details>

<summary>May 2024 Practice Problems</summary>

<br>

1. Day 153 - May 1st 2024: [International Call Percentage from DataLemur](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day153.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Started by creating a CTE and doing a LEFT JOIN twice, once to join caller id on caller id and once to join receiver id on caller id. This allowed me to find the location of every person in the dataset. I then used a CASE statement in combination with the SUM() function to check for instances where the caller's country is not equal to the receiver's country, meaning it's an international call. I also used COUNT() to count the total number of calls. With that CTE complete, I wrote a query that divided the international calls by the total calls and multiplied by 100 to get the international call percentage. I used the ROUND() function to round the output to 1 decimal place
2. Day 154 - May 2nd 2024: [Combine Two Tables from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day154.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .merge() function to join the employee names on the employee locations, being sure to keep all employee names even if they don't exist in the location table. Used the .sort_values() function to order by first name alphabetically, then selected the first name, last name, and state from the dataframe
3. Day 155 - May 3rd 2024: [Big GDP from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day155.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Performed dataframe filtering to filter by GDP and used the .sort_values() function to order by the country name alphabetically, then selected the country from the dataframe
4. Day 156 - May 4th 2024: [Shopping Cart Conversions from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day156.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation to engineer a new feature, specifically the percentage of items that customers put in their cart that they actually bought. Used the .round() function to round to two decimal places and the .sort_values() function to sort by customer id
5. Day 157 - May 5th 2024: [Most Orders from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day157.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .max() function to find the maximum number of orders and stored it in a variable. Then filtered the dataframe to records where the max number of orders was equal to the number of orders
6. Day 158 - May 6th 2024: [Duplicate Emails from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day158.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .count() function and the .groupby() function to count the number of emails and group by email, also used the .reset_index() function and .rename() function to name the new column email_count. I then filtered the dataframe on email_count to find instances where the email count was greater than 1, singling out users with duplicate emails. I used the .sort_values() function to order the output by email alphabetically
7. Day 159 - May 7th 2024: [Heart Attack Risk from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day159.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the & symbol and inequalities to filter on multiple conditions that would put a patient at risk of a heart attack. Used the .sort_values() function to order by cholesterol descending since that's the most important indicator
8. Day 160 - May 8th 2024: [Wealthy Customers from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day160.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Filtered the dataframe to customers that spent at least 500 dollars in a single order, then used the .nunique() function to count the unique number of customers
9. Day 161 - May 9th 2024: [Movie Theater from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day161.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the | operator to filter a dataframe on multiple values
10. Day 162 - May 10th 2024: [Ice Cream Popularity from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day162.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used comparison operators to compare two fields for the purpose of filtering a dataframe. Used the .sort_values() function to order the output by ice cream flavor alphabetically
11. Day 163 - May 11th 2024: [Gamer Tags from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day163.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used string slicing to select part of a string, the .split() function to select part of a date, and performed string concatenation using the + symbol. Used the .sort_values() function to order the output by gamer tag
12. Day 164 - May 12th 2024: [Medium Sized Countries from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day164.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the & operator in combination with inequalities to filter the dataframe to countries that have a population within the specified range. Used the .sort_values() function to order by population
13. Day 165 - May 13th 2024: [Million Dollar Store from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day165.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .groupby() function to group the dataframe by store id, the .mean() function to find the average revenue, and the .round() function to round the output to 2 decimal places. I then filtered the dataframe by revenue and used the .sort_values() function to order the dataframe by store id
14. Day 166 - May 14th 2024: [Big Countries from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day166.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the | symbol to filter the dataframe to countries that met at least one of the specified conditions, used the .sort_values() function to order by country alphabetically
15. Day 167 - May 15th 2024: [Low Quality YouTube Video from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day167.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation with pre-existing fields to engineer a new feature, the like percentage of a video. I then filtered the dataframe based on the like percentage and used the .sort_values() function to order the output by video id
16. Day 168 - May 16th 2024: [Device First Used from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day168.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .groupby() function and the .min() function to find the earliest date a game was played grouped by device. Filtered the dataframe by game and used the .sort_values() function to order by the date
17. Day 169 - May 17th 2024: [Tesla Models from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day169.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation to engineer a new feature, the profit made selling a car. Used the .sort_values() and .head() functions to grab the record with the highest profit
18. Day 170 - May 18th 2024: [Profit Margin from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day170.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation with existing fields to engineer a new feature, the profit margin for each product. Used the .round() function to format the numbers to a uniform number of decimals, and used the .sort_values() function to order by profit descending and product name ascending
19. Day 171 - May 19th 2024: [On The Way Out from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day171.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the pd.to_datetime() function to convert the birth date field to a datetime. I then used the .sort_values() and .head() functions together to only output the three oldest employees working at a company
20. Day 172 - May 20th 2024: [Area Code from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day172.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .str() function to perform string slicing with the purpose of filtering to phone numbers that start with a specified area code
21. Day 173 - May 21st 2024: [Most Reviewed Restaurant from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day173.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .transform() function on the comment column to count the number of comments and the .transform() function on the rating column to find the mean/average rating. Used the .groupby() function while calculating both of those to group by restaurant, used the .sort_values() function to order by comment count and average rating descending, and used the .head() function to only output the most reviewed restaurant
22. Day 174 - May 22nd 2024: [Rotten Drama from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day174.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Calculated the difference between Rotten Tomato ratings and user ratings, then used the abs() function to make all output positive. Used the .sort_values() and .head() functions together to select the biggest rating difference
23. Day 175 - May 23rd 2024: [Car Failure from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day175.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used inequalities to filter a dataframe on multiple conditions. Used the .sort_values() keyword to order by name alphabetically
24. Day 176 - May 24th 2024: [Best Classes from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day176.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .mean() function to calculate the average grade and the .groupby() function to group by class. Used the .sort_values() function to order by the average grade descending
25. Day 177 - May 25th 2024: [Homes Built from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day177.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the & symbol and inequalities to filter a dataframe on multiple conditions
26. Day 178 - May 26th 2024: [Costco Rotisserie Loss from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day178.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .sum() function to find the total revenue lost and used the .round() function to round to the nearest whole number. Also used the .astype() function in to convert the number from a float to an int and drop the decimal place
27. Day 179 - May 27th 2024: [Baseball Scouts from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day179.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the numpy .where() function to make a skill level column that assigns players a level based on their batting average
28. Day 180 - May 28th 2024: [Men vs Women from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day180.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .mean() function to calculate the average purchase price and the .round() function to round the output to 2 decimal places. Used the .groupby() and .sort_values() functions to group and order by gender
29. Day 181 - May 29th 2024: [Obesity from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day181.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used a formula to calculate BMI, which included the use of the ** symbol to calculate a power. Used the .round() function to round the output to 2 decimal places and filtered the dataframe based on BMI
30. Day 182 - May 30th 2024: [Perfect Data Analyst from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day182.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Checked the fields for a certain value to determine if a candidate met specific job qualifications and used the & and | comparison operators to filter the data frame
31. Day 183 - May 31st 2024: [Chocolate from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/may2024/day183.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .str() function in combination with the .contains() function to filter the dataframe to all items that have the word chocolate anywhere in their name

</details>



### June 2024

<details>

<summary>June 2024 Practice Problems</summary>

<br>

1. Day 184 - June 1st 2024: [Apply Discount from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day184.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the | operator to filter the dataframe to customers that met the conditions for receiving a discount, then used the .count() function to count the number of customers that met the conditions
2. Day 185 - June 2nd 2024: [Electric Bike Replacement from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day185.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Filtered the dataframe to filter to electric bikes that need to be replaced due to a high level of battery usage, then used the .count() function to count how many bikes need to be replaced
3. Day 186 - June 3rd 2024: [Average Revenue from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day186.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .groupby(), .mean(), and .reset_index() functions to find the average revenue and group the average revenue by store id. I then used the .sort_values() function to order by average revenue so the top earning stores showed at the top of the output table
4. Day 187 - June 4th 2024: [A/B Students from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day187.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the | operator to filter the dataframe to students who got an A or B for their final exam. Also used the .sort_values() function to order the output alphabetically
5. Day 188 - June 5th 2024: [Web Traffic from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day188.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .groupby() function to group the dataframe by visit date and used the .nunique() function to get the distinct count of visitors. Used the .sort_values() function to order the output by date sequentially
6. Day 189 - June 6th 2024: [Football Perfection from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day189.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the & symbol to filter the dataframe to football teams that had both a high number of points scored and a low number of penalties
7. Day 190 - June 7th 2024: [Animals from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day190.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the pd.concat() function to combine two datasets with common columns and remove any duplicates, used the .sort_values() function to order output alphabetically
8. Day 191 - June 8th 2024: [Sandwich Generation from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day191.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Performed the equivalent of a SQL CROSS JOIN in Python. Accomplished this by making a new column in each dataframe with the same name and value, then used pd.merge() to join the dataframes on the new common column. I then used .drop() to drop the common column and used the .sort_values() function to order the output alphabetically on bread name and meat name
9. Day 192 - June 9th 2024: [Unique from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day192.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .drop_duplicates() function to drop any duplicate customer ids from the dataframe, then used the .sort_values() function to order the output alphabetically by customer id
10. Day 193 - June 10th 2024: [Uber High and Low from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day193.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the | symbol to filter a dataframe on two separate conditions, used the .sort_values() function to order the output on income
11. Day 194 - June 11th 2024: [Fire Them! from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day194.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the & symbol to filter a dataframe on multiple conditions and wrote a formula to calculate the proportion of tasks that each employee has completed for the purpose of filtering. Used the .sort_values() function to order the output alphabetically on name
12. Day 195 - June 12th 2024: [Market Caps from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day195.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation to calculate market capitalization and used the ROUND() function to round output to 2 decimal places. Used the ORDER BY keyword to order the output by market capitalization descending
13. Day 196 - June 13th 2024: [Market Caps from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day196.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Performed a calculation to calculate market capitalization and used the .round() function to round output to 2 decimal places. Used the .sort_values() function to order the output by market capitalization descending
14. Day 197 - June 14th 2024: [Shrink-flation from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day197.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation to calculate the percent difference in item size and price, using the ROUND() function to round the percentages to the nearest whole number. Used a CASE statement to output "True" if an item decreased in size and increased in price, and "False" otherwise. Used the ORDER BY keyword to order the output alphabetically by item name
15. Day 198 - June 15th 2024: [Biggest Country Debts from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day198.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used a subquery in the WHERE clause to filter to where the year is equal to the MAX() year in the dataset, allowing the query to work in the future without any manual adjustments. Used the ORDER BY keyword to order by national debt descending and used the LIMIT keyword to grab only the top 3 countries with the highest debt. Used the ROUND() function to round the national debt to the nearest whole number in the output table
16. Day 199 - June 16th 2024: [Calculator Sales from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day199.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Started off by creating a CTE. In the CTE, I used the SUM() function and CASE statements to sum up the calculator sales for 2000 and 2023, storing both values in variables. In the outer query, I used the variables from the CTE to calculate the percent change in calculator sales between 2000 and 2023, using the ROUND() function to round the output to two decimal places
17. Day 200 - June 17th 2024: [Make it Cleaner! from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day200.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used multiple CASE statements to perform data cleaning on various columns. I first used a CASE statement to return NULL for product ids that were not greater than 0. I then used another CASE statement to return 0 for any values that were not greater than 0 in the quantity sold column. Finally, I used a CASE statement to plug in the dataset's average revenue for any NULL values in the revenue column. I used a small subquery within the CASE statement to SELECT the dataset's average revenue value
18. Day 201 - June 18th 2024: [Boss from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day201.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .merge() function to perform a self join and get employee names and boss names on the same row for the purpose of finding the boss for each employee. Performed a LEFT merge specifically to keep all employee data even if they don't have a boss. Used the .sort_values() function to get the output in alphabetical order
19. Day 202 - June 19th 2024: [Average Gaming Session from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day202.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Started by filtering the dataframe to gaming activities. I then used the .mean() function along with the .groupby() function to find average time spent on gaming grouped by user
20. Day 203 - June 20th 2024: [Kroger's Members from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day203.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation using the .count() function to calculate the percentage of Kroger shoppers that have a membership card, used the .round() function to round to two decimal places
21. Day 204 - June 21st 2024: [Big Pharma from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day204.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation to calculate the amount of money lost on different drugs. Used the .abs() function and .round() function to get the absolute value of money lost rounded to 1 decimal place, then filtered the dataframe to drugs that had a negative profit. I then returned the top three drugs that lost the most money by using the .head() function. There ended up being only two drugs that had lost money, so the final output table had two drugs
22. Day 205 - June 22nd 2024: [Gmail Users from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day205.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .str.contains() method and a regular expression to select all users who use Gmail as their email provider, AKA all emails that end in @gmail.com
23. Day 206 - June 23rd 2024: [LinkedIn Famous from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day206.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation to determine the popularity score of LinkedIn posts based off their impressions and interactions. I then filtered the dataframe and used the .sort_values() function to get posts only of a specified popularity level, sorted by popularity level descending
24. Day 207 - June 24th 2024: [Python If-Else from HackerRank](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day207.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Set up a conditional statement that outputted different messages based on a few different conditions. Used the modulo operator (%) to to evaluate if numbers were even or odd and used inequalities to determine the range of the numbers for the purpose of printing out the different messages
25. Day 208 - June 25th 2024: [Arithmetic Operators from HackerRank](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day208.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Practiced the syntax for using the arithmetic operators in Python, including addition (+), subtraction (-), and multiplication (*)
26. Day 209 - June 26th 2024: [Python: Division from HackerRank](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day209.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Learned about the difference between integer division (//) and float division (/), and wrote code to practice the syntax for both
27. Day 210 - June 27th 2024: [Loops from HackerRank](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day210.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Practiced setting up for loops, printing out the square root of each number less than the number that a user inputted
28. Day 211 - June 28th 2024: [Combine Two Tables from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day211.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the Pandas .merge() method to perform a left join on two different tables
29. Day 212 - June 29th 2024: [Duplicate Emails from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day212.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the Pandas .duplicated() method to select all duplicate emails in a dataframe, then used the .drop_duplicates() method to output each email that had a duplicate only once in the output table
30. Day 213 - June 30th 2024: [Customers Who Never Order from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/june2024/day213.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the Pandas .isin() method in combination with the negation operator ~ to filter the dataframe to instances where a customer showed up in the customers table but not the orders table. I then used the Pandas .rename() method to rename the 'name' column to 'Customers' to match the desired output. Finally, I returned the Customers column from the dataframe

   
</details>



### July 2024

<details>

<summary>July 2024 Practice Problems</summary>

<br>

1. Day 214 - July 1st 2024: [Big Countries from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day214.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the | operator to filter a dataframe based on whether it met at least one of two criteria for a country to be considered big
2. Day 215 - July 2nd 2024: [Article Views I from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day215.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: I started by filtering the dataframe to instances where the author id was equivalent to the viewer id to find instances where the author viewed one of their own articles. I then used the .unique() method on the author id column to grab each unique author that viewed at least one of their own articles, then used pd.DataFrame to convert the array of author ids to a dataframe. Finally, I used the .sort_values() function to sort the output table by the ids ascending
3. Day 216 - July 3rd 2024: [Fix Names in a Table from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day216.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: For this problem, I needed to fix the capitalization of names in a table so that the first letter was uppercase and the rest were lowercase; I completed this in two different ways. For the first solution, I simply used the Python string .capitalize() method, which capitalizes the first character in a string and makes the rest lowercase. For the second solution, I used string slices combined with the string .upper() and .lower() methods to accomplish the same output. For both solutions, I used the .sort_values() function to order the output by user id ascending
4. Day 217 - July 4th 2024: [Invalid Tweets from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day217.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: First I used the str.len() method to find the length of strings in a column. I then used that to filter the dataframe to strings with greater than 15 characters, grabbing invalid tweets that surpassed the character limit
5. Day 218 - July 5th 2024: [Recyclable and Low Fat Products from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day218.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the & operator to filter to products that are both recyclable and low fat
6. Day 219 - July 6th 2024: [Calculate Special Bonus from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day219.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: For this question, employees are supposed to get a bonus worth 100% of their salary if their employee id is odd and their name does not start with M - otherwise, they get a bonus of 0. To accomplish this, I first defined the bonus column and set it equal to 0. Then I used the .loc[] method to find employees that met both conditions and inserted their salary into the bonus column. To find odd employee ids I used the modulo (%) operator, and to find names that do not start with M I used a combination of the str.startswith() method and the negation (~) operator. I then used the .sort_values() function to order the output by employee id
7. Day 220 - July 7th 2024: [Employee Bonus from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day220.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: For this question, the goal was to output all employees with a bonus less than 1000. I started by using .merge() to perform an outer join on the employee and bonus table. I then performed dataframe filtering to select employees with bonuses less than 1000, making sure to use the .isna() method in combination is the or (|) operator to also select employees with a bonus of 0
8. Day 221 - July 8th 2024: [Find Customer Referee from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day221.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: For this question, the goal was to output all customers that were not referred by the customer with an id of 2. To accomplish this, I performed dataframe filtering using the or (|) operator to select customers that didn't have a 2 in the referee_id column, as well as using the .isna() method to select customers that didn't get referred by anyone and therefore had a NULL value in the referee_id column
9. Day 222 - July 9th 2024: [Game Play Analysis I from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day222.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: For this question, the goal was to find the first login date for all users in the dataset. I started by using the .groupby() method to group the dataframe by player id, then found the .min() of the event_date field. I then used .reset_index() to change the player id field back into a column and .rename() to change the name of the event date field to 'first_login'
10. Day 223 - July 10th 2024: [Not Boring Movies from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day223.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: For this question, the goal was to find movies with an odd id and a description that doesn't say "boring". I found the odd movie ids using the modulo (%) operator, then used the and (&) operator to also filter to instances where the movie description was not equal (!=) to boring. I finished off the question by using the .sort_values() function to order the output by movie rating descending
11. Day 224 - July 11th 2024: [Swap Salary from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day224.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: Used the .replace() method to swap all 'f' and 'm' values - values of 'f' became 'm', and values of 'm' became 'f'
12. Day 225 - July 12th 2024: [Product Sales Analysis I from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day225.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: In this question I used the .merge() method to perform an inner join on two tables, returning the product name, year, and price for each sale id that appeared in the sales table
13. Day 226 - July 13th 2024: [Replace Employee ID With The Unique Identifier from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day226.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: In this question I used the .merge() method to perform a left join on two tables. Performing the left join allowed me to keep all the users in the output table even if the user didn't have a unique id
14. Day 227 - July 14th 2024: [Bank Account Summary II from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day227.md)
    - Languages Used: Python
    - Question Difficulty: Easy
    - Concepts Covered: For this question, the goal was to find bank accounts with a balance of over 10,000 across all transactions. I started by using the .merge() method to perform an inner join on the users and transactions tables. I then used .groupby() and .sum() to group the combined dataframe by account and add up the balance. Next, I used .merge() again to left join the balance dataframe to the combined dataframe on the account field. Finally, I filtered to accounts that had a balance of over 10,000 and used the .drop_duplicates() method to show each account only once
15. Day 228 - July 15th 2024: [SuperCoolElectronicsStore.com from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day228.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used a lambda function in combination with the .apply() method to make a new column that kept track of which storage type (SSD or HDD) was in the laptop name. Used the .sort_values() function to order by the laptop id ascending
16. Day 229 - July 16th 2024: [Food Divides Us from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day229.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .groupby() method, .sort_values() method, and .head() method to group the .sum() of fast food spending by region, order the output based on total spending per region descending, and grab the top spending region
17. Day 230 - July 17th 2024: [Biggest Country Debts from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day230.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Performed dataframe filtering to filter to where the year is equal to the .max() year in the dataset, allowing the query to work in the future without any manual adjustments. Then used the .sort_values method to order by national debt descending and used the .head() method to grab only the top 3 countries with the highest debt. Used the .round() function to round the national debt to the nearest whole number in the output table
18. Day 231 - July 18th 2024: [Intern Problems from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day231.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .replace() method to change 'Yes' to 'Y' and 'No' to 'N', making the column have uniform formatting throughout
19. Day 232 - July 19th 2024: [Movie-aholic from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day232.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: First I used .merge() to join two dataframes with customer data and data on the movies they watched. Then I used .groupby() and .count() to count the number of movie ids grouped by customer name. Next, I used the .sort_values() method to order output by the number of movies descending. Finally, I used the .head() method to only return the name of the customer that had watched the most movies
20. Day 233 - July 20th 2024: [Tech Layoffs from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day233.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation to find the percentage of the company that got laid off from their job and used the .round() function to clean up the output into a uniform number of decimals. Used the .sort_values() method to sort the output by company name alphabetically
21. Day 234 - July 21st 2024: [Football Attendance from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day234.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .groupby() method to group the attendance by season, used the .sum() aggregation to add up total season attendance, then used the .sort_values() and .head() methods together to only output the season with the top attendance
22. Day 235 - July 22nd 2024: [Water Pollution from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day235.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .groupby() method to group the .mean() pollution concentration by pollutant, then used the .round() method to round the concentration values to two decimal places. I then filtered the dataframe to find pollutants wih a high concentration level and used the .sort_values() method to order by pollutant alphabetically
23. Day 236 - July 23rd 2024: [Media Addicts from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day236.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .merge() method to combine two datasets with information about how much time a user spent on social media and the name of each user. Then performed dataframe filtering to filter to users that spent more time on social media than the .mean(), returning the first name of users with above average usage in alphabetical order with the help of the .sort_values() keyword
24. Day 237 - July 24th 2024: [Computer Replacement from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day237.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used datetime.datetime and datetime.timedelta from the Python datetime module to subtract 5 years from the date 1/1/2023. I then used pd.to_datetime() to convert the data type of the date_activated field to datetime, then performed dataframe filtering to filter to computers that were activated over five years ago so they can be replaced
25. Day 238 - July 25th 2024: [TMI (Too Much Information) from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day238.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .str.split() method to split a field with customer's first and last names into two based on the position of the space. Then used string indexing to return the first half of the string, only selecting the first names
26. Day 239 - July 26th 2024: [Pepperoni-flation from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day239.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Filtered the dataframe to pizza orders that had pepperoni as a topping, then performed a calculation using the .count() aggregation to calculate how much money a pizza restaurant would save by putting less pepperoni on their pizzas
27. Day 240 - July 27th 2024: [Separation from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day240.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: In this question, user ID's and user first names were accidentally combined into one string. I used string slicing to make a separate field for the ID's and a separate field for the names
28. Day 241 - July 28th 2024: [Ranking Students from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day241.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .rank() function to assign students a rank number based on their grade, assigning students with the same grade value the same rank number by setting the method to dense. Used the .sort_values() method to order by both ranks descending and names alphabetically, that way students with the same ranks still have a defined order
29. Day 242 - July 29th 2024: [2022 Orders from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day242.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .merge() method to join two datasets on common columns. I then used pd.to_datetime() to convert the join_date and order_date columns to datetime columns. Then I used .dt.year from the datetime module to filter to instances where customers made an order in the same year they created their account. Finished by using the .sort_values() method to order by user id ascending
30. Day 243 - July 30th 2024: [Bad Bonuses from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day243.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .isin() method in combination with the negation operator ~ to filter to employees who weren't found in the bonus table. Used the .sort_values() method to order the output by employee id ascending
31. Day 244 - July 31st 2024: [Must Buy it All from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/july2024/day244.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .groupby() and .nunique() methods to count the unique product id grouped by customer id, then filtered the dataframe to customers that had bought all 4 available products

</details>



### August 2024

<details>

<summary>August 2024 Practice Problems</summary>

<br>

1. Day 245 - August 1st 2024: [Employee Turnover from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day245.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Started by using the pd.to_datetime() method to convert the date_left column to a datetime data type. I then used dt.year from the datetime module to select only the year in the date_left column and used .apply() in combination with a lambda function to make a new column that had a value of 1 if the year was 2022, and a value of None otherwise. Finally, I divided the .count() of employees that quit in 2022 by the .count() of all employees and multiplied by 100 to get the percentage of employees that quit in 2022
2. Day 246 - August 2nd 2024: [Greenhouse Gases from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day246.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used .groupby(), .sum(), .round(), .reset_index(), and .rename() to calculate total carbon emissions grouped by country, rounded to one decimal place and renamed to total_emissions. Then used the .sort_values() and .head() keywords to find the country with the most total carbon emissions
3. Day 247 - August 3rd 2024: [Company Wide Increase from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day247.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Created a function that determined the new salary for each employee depending on the pay level they were on, then used the .apply() method to apply the function to the dataframe and engineer a new column. I made a separate function rather than using a lambda function in this case because I thought it looked cleaner and made the code a bit easier to read
4. Day 248 - August 4th 2024: [Cloud Storage Fees from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day248.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Performed a calculation to see which users had gone over their alloted 200gb of cloud storage, then filtered the dataframe to those users so that they could pay a fee. Used the .abs() method to get the result in absolute value and used the .sort_values() method to order by fees descending
5. Day 249 - August 5th 2024: [Bike Price from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day249.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Started by filtering the dataframe to instances where the bike was sold, also used the .isna() method in combination with the not ~ operator to exclude bikes that were donated. I then used .mean() and .round() to find the average bike price rounded to 2 decimal places
6. Day 250 - August 6th 2024: [Employee Raise from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day250.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Started by creating the row_num variable. I used .sort_values() to sort by salary ascending, .groupby() to group by department, and .cumcount() + 1 to assign a row number based on salary in each department. I then filtered the row_number variable to 1 to get the lowest paid employees of each department, and performed a calculation to give them a raise and determine their new salary. Used the ORDER BY keyword to sort the output by new salary descending
7. Day 251 - August 7th 2024: [Senior Citizen Discount from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day251.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Started by using datetime.datetime from the datetime module to store the current date in a variable. I then used pd.to_datetime() to convert the birth date column to a datetime data type, then subtracted the birth date from the current date. I then used dt.days on that calculation and divided by 365 to calculate how old each person in the dataset was. Finally, I used dataframe filtering to filter to customers 55 and above and used the .sort_values() method to order the output by customer_id ascending
8. Day 252 - August 8th 2024: [Buying Less from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day252.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Made two different dataframes, both grouped by customer_id, but one that uses .sum() on the order total column and one that uses .count() on the order total column. I then used .merge() to perform an outer join on these two dataframes, getting the total spending and number of orders into one dataframe. Finally, I used those variables to filter to customers that don't buy as much as the company would like
9. Day 253 - August 9th 2024: [Crew Overspending from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day253.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used .groupby(), .sum(), and .reset_index() to calculate the total amount spent grouped by employee_id and name the column total_amount_spent. I then created an amount_owed column by using the .apply() method in combination with a lambda function to calculate if employees spent over $100 for food. I finished off by using the .sort_values() method to order by amount_owed descending and employee_id ascending
10. Day 254 - August 10th 2024: [Amazon Returns from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day254.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .groupby() method to group by order id - each product bought had its own row even if they were part of the same order, so this was necessary to look at the order total as a whole rather than by each item. I then used the .agg() method to calculate the sum of both the product price and the estimated return price. Finally, I used those values to filter the dataframe to instances where the potential profit of the entire order was less than the estimated return price of the entire order
11. Day 255 - August 11th 2024: [Richie Rich from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day255.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used datetime.datetime and datetime.delta from the datetime module to subtract 3 years from a specified date. Used the pd.to_datetime() method to convert the year column to a datetime field, then filtered the dataframe to where the year column is from 3 years ago or later. I then used .groupby() and .sum() to calculate total profit grouped by company. Next, I filtered the dataframe again to only select companies with a profit of over 20 million. Finally, I used the .sort_values() method to order by company alphabetically
12. Day 256 - August 12th 2024: [Shrink-flation from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day256.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Performed calculations to calculate the percent difference in item size and price, using the .round() method to round the percentages to the nearest whole number. Used the .apply() method in combination with a lambda function to output "True" if an item decreased in size and increased in price, and "False" otherwise. Used the .sort_values() method to order the output alphabetically by item name
13. Day 257 - August 13th 2024: [Above Average from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day257.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used a HAVING clause and used a small subquery to filter to instances where the average height of a country was larger than the overall average height in the dataset. Finished off with the ORDER BY keyword to order the output by average country height descending
14. Day 258 - August 14th 2024: [Taxes from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day258.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Calculated the taxes owed by each company by multiplying their taxable income by the tax rate. Then added a WHERE clause and used a small subquery to filter to instances where the fiscal year was equal to the MAX() fiscal year in the dataset, allowing me to view only the data for the most recent year. Finished off with the ORDER BY keyword to order the output by taxes owed descending
15. Day 259 - August 15th 2024: [Traffic Control from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day259.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: Used the UNION keyword to combine two datasets on domestic flights and international flights. Made sure to grab the columns from the domestic flights dataset first so that the names of the columns in the output table followed the naming scheme of that dataset. Also used the WHERE keyword to filter the second dataset to a specific international zone
16. Day 260 - August 16th 2024: [Running Average from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day260.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: Used a window function to find the AVG() of daily sales with a PARTITION BY store id and an ORDER BY sale date ascending, giving me the running average of sales for each store. Used the ORDER BY keyword to order by store id and sale date ascending
17. Day 261 - August 17th 2024: [Different Averages from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day261.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: In this problem I calculated the average of sales data that includes NULL values three different ways. First I simply used AVG() to calculate the average without accounting for the NULL values. Next, I used a CASE statement in combination with the IS NULL keyword to insert a 0 for NULL values, then divided the SUM() of the sales by the COUNT() of that CASE statement to calculate the average. Finally, I used a small subquery within a CASE statement to insert the MIN() sale amount for each null value, then used AVG() on that CASE statement to calculate the average
18. Day 262 - August 18th 2024: [Above Average from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day262.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the .mean() function to filter the dataframe to instances where the average height of a country was larger than the overall average height in the dataset. Finished off with the .sort_values() function to order the output by average country height descending
19. Day 263 - August 19th 2024: [Help Desk Manager from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day263.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Performed dataframe filtering then used the .groupby() function in combination with the .count() function to tally the number of calls that had been resolved. I then used the .groupby() and .count() functions on the unfiltered dataframe to tally the total number of calls. Then I used .merge() to combine the dataframes with the resolved callsa and total calls together, then calculated the percentage of calls resolved. I finished off by using the .sort_values() function to order the output alphabetically by employee name
20. Day 264 - August 20th 2024: [Multi-Level Marketing from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day264.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: Used the pd.to_datetime() function to convert the date column to a datetime data type, then used .dt.month from the datetime module to extract the month from the date field and store it in a new column. I then used the .groupby() function to group by the new month column and used .sum() to add up the profit for each month. Next, I used dataframe filtering to filter to the first six months of the year and to months where profit was positive. Finally, I used the .sort_values() function to order the output descending by profit
21. Day 265 - August 21st 2024: [Unions from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day265.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: I started off by using the .rename() method to rename the columns in the med_list table to match the naming scheme of the medication_information table so that the two would have common columns. I then used the pd.concat() method to union the two tables and used the .sort_values() function to order the output alphabetically by medication name
22. Day 266 - August 22nd 2024: [Full Time Jobs from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day266.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: I used the .rename() method to rename the columns in the job_two table to match the naming scheme of the job_one table so that the two would have common columns. I then used the pd.concat() method to union the two tables, then performed dataframe filtering to filter to only full-time jobs. I then used the .groupby() method to group the dataframe by name and the .count() function to count the number of full-time jobs per person. Finally, I filtered the dataframe to find the employees that have more than one full-time job
23. Day 267 - August 23rd 2024: [Calculator Sales from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day267.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: I started off by writing lambda functions that only count the calculator sales if they're in a certain year, then used the .apply() function to apply the lambda function to the dataframe. I then used the .sum() function on the .apply() functions to add up the total calculator sales for 2000 and 2023. I performed a calculation to calculate the percent difference between those two years and made it a column in the dataframe since the answer being part of a dataframe was a requirement of the problem. I then used the .drop_duplicates() function so that the percentage change was only displayed once
24. Day 268 - August 24th 2024: [Product Launch from Analyst Builder](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day268.md)
    - Languages Used: Python
    - Question Difficulty: Medium
    - Concepts Covered: I started by performing dataframe filtering to create two separate dataframes filtered to 2022 and 2023. I then used .groupby(), .size(), and .reset_index() together to group the dataframes by company name and count the products launched. I then used pd.merge() to perform an outer join on the 2022 dataframe and the 2023 dataframe, getting the values for both years into one dataframe. Next, I used the .fillna() function to change any null values to 0. With that done, I was able to subtract the number of product launches in 2022 from the number of product launches in 2023 and store it in a new column called difference. I finished off by returning the company name column and difference column and using the .sort_values() function to order the output by company name alphabetically
25. Day 269 - August 25th 2024: [Employees Earning More Than Their Managers from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day269.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Performed a self JOIN with the employees table on the employee id and manager id. I then used the WHERE keyword to filter to instances where the employee salary was greater than the manager salary
26. Day 270 - August 26th 2024: [Classes More Than 5 Students from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day270.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the HAVING keyword in combination with the COUNT() function to filter to instances where a class had at least 5 students
27. Day 271 - August 27th 2024: [Customer Placing the Largest Number of Orders from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day271.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the ORDER BY keyword to sort the output table by the COUNT() of orders descending, then used the LIMIT keyword to grab the customer with the most orders
28. Day 272 - August 28th 2024: [Top Travellers from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day272.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Started off by performing a LEFT JOIN, keeping all data from the users table and matching data from the rides table. I then used the SUM() function to calculate the total travel distance, then did a GROUP BY name and user_id to see the travel distance for each user. I used the COALESCE() function to replace NULL travel distances with 0, then used the ORDER BY keyword to sort the output by travel distance descending and name ascending
29. Day 273 - August 29th 2024: [Patients With a Condition from LeetCode](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day273.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the LIKE keyword to select all rows where the condition column includes the 'DIAB1' prefix, meaning the patient has Type 1 diabetes
30. Day 274 - August 30th 2024: [Retrieve Everything From a Table from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day274.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the * symbol to retrieve all columns and rows from the facilities dataset
31. Day 275 - August 31st 2024: [Retrieve Specific Columns From a Table from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/august2024/day275.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the SELECT keyword to output the name and member cost for each facility in the facilities table
      
</details>



### September 2024

<details>

<summary>September 2024 Practice Problems</summary>

<br>

1. Day 276 - September 1st 2024: [Control Which Rows Are Retrieved from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day276.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the WHERE keyword to filter to facilities that have a membership fee
2. Day 277 - September 2nd 2024: [Control Which Rows Are Retrieved - Part 2 from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day277.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: I started off by using the WHERE keyword to filter to facilities that have a membership fee. I then used the AND keyword and performed a calculation to filter to facilities whose membership fee are less than 1/50th of the monthly maintenance cost
3. Day 278 - September 3rd 2024: [Basic String Searches from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day278.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the LIKE keyword in combination with the wildcard symbol % to filter to facilities that have the word Tennis anywhere in its name
4. Day 279 - September 4th 2024: [Matching Against Multiple Possible Values from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day279.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the IN keyword in combination with the WHERE keyword to filter to facilities with specific id numbers
5. Day 280 - September 5th 2024: [Classify Results Into Buckets from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day280.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used a CASE statement to create a new column that says 'expensive' or 'cheap' depending on the monthly maintenance fee
6. Day 281 - September 6th 2024: [Working With Dates from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day281.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the DATE_TRUNC() function in the WHERE clause to filter to members who joined in or after September 2012
7. Day 282 - September 7th 2024: [Removing Duplicates and Ordering Results from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day282.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the DISTINCT() keyword to grab each unique member surname, then used the ORDER BY keyword to sort the output table alphabetically and the LIMIT keyword to grab the first 10 surnames
8. Day 283 - September 8th 2024: [Combining Results From Multiple Queries from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day283.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the UNION keyword to combine the output of two queries
9. Day 284 - September 9th 2024: [Simple Aggregation from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day284.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: Used the MAX() keyword to find the singup date of the member who joined most recently
10. Day 285 – September 10th 2024: [More Aggregation from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day285.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: This problem required identifying the most recent member(s) who joined. I used a subquery to find the maximum joindate from the members table, then filtered the main query to return only those members whose joindate matched this maximum. This approach demonstrated the use of aggregation functions and subqueries to perform targeted filtering within a query
11. Day 286 – September 11th 2024: [Count the Number of Facilities from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day286.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: This problem involved counting the total number of facilities in the facilities table. I used the COUNT() function to return the total number of rows in the table
12. Day 287 – September 12th 2024: [Count the Number of Expensive Facilities from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day287.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: This problem involved counting the number of facilities where the guest cost is 10 or more. I used the COUNT() function with a WHERE clause to filter the rows where guestcost is greater than or equal to 10 before performing the count
13. Day 288 – September 13th 2024: [Count the Number of Recommendations Each Member Makes from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day288.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: This problem involved counting how many recommendations each member has made. I used the COUNT() function with a WHERE clause to filter out rows where recommendedby is NULL, then grouped by recommendedby to count the recommendations per member and ordered the result by member ID
14. Day 289 – September 14th 2024: [List the Total Slots Booked Per Facility from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day289.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: This problem involved listing the total number of slots booked per facility. I used the SUM() function to aggregate the number of slots for each facility (facid), grouping by facid and ordering the results by facility ID
15. Day 290 – September 15th 2024: [List the Total Slots Booked per Facility in a Given Month from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day290.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: This problem required listing the total number of slots booked per facility for September 2012. I used the SUM() function on the slots column, grouping by facid and restricting the data to September 2012 using DATE_TRUNC(). The results were ordered by the total number of slots
16. Day 291 – September 16th 2024: [List the Total Slots Booked Per Facility Per Month from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day291.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: This problem required listing the total slots booked per facility for each month in 2012. I used the SUM() function to aggregate slots, grouping by both facid and the month, which I extracted from the starttime field by using the DATE_PART() function. I then used the DATE_TRUNC() function to filter to 2012 and sorted by facid and month
17. Day 292 – September 17th 2024: [Find the Count of Members Who Have Made at Least One Booking from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day292.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: This problem required counting the number of unique members who have made at least one booking. I used the COUNT() function with the DISTINCT() keyword to return the total number of distinct member IDs
18. Day 293 – September 18th 2024: [List Facilities with More Than 1000 Slots Booked from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day293.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: This problem required listing facilities with more than 1000 total slots booked. I used the SUM() function to aggregate slots per facility and applied the HAVING clause to filter results, ensuring only facilities with over 1000 slots were included
19. Day 294 – September 19th 2024: [Find the Total Revenue of Each Facility from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day294.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: This problem involved calculating the total revenue for each facility. I performed a JOIN to join the facilities table with the bookings table on the facid field. I then used the SUM() function with a CASE statement to account for different costs for members and guests, grouping the results by facility name and sorting by revenue
20. Day 295 – September 20th 2024: [Find Facilities with a Total Revenue Less Than 1000 from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day295.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: This problem required finding facilities with a total revenue under 1000. I used a WITH clause to create a CTE, used a JOIN to join the facilities and bookings table, calculated revenue using a CASE statement, and then filtered the results for those under 1000 outside the CTE
21. Day 296 – September 21st 2024: [Output the Facility ID That Has the Highest Number of Slots Booked from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day296.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: This problem involved finding the facility with the most slots booked. I used the WITH keyword to create a CTE that calculated total slots per facility and assigned rankings using the ROW_NUMBER() window function. I then used that CTE in another query to filter for the top-ranked facility using the WHERE keyword
22. Day 297 – September 22nd 2024: [Retrieve the Start Times of Members' Bookings from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day297.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: This problem required retrieving the start times for bookings made by David Farrell. I performed an INNER JOIN between the bookings and members tables, filtering for rows WHERE the member's first name is 'David' and the last name is 'Farrell'
23. Day 298 – September 23rd 2024: [Work Out the Start Times of Bookings for Tennis Courts from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day298.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: This problem required retrieving start times for bookings of two specific tennis courts on a given day. I used an INNER JOIN between the bookings and facilities tables, then used the WHERE keyword to filter. I leveraged DATE_TRUNC() to filter by day and the IN keyword to filter for specific court names. The results were ordered by start time
24. Day 299 – September 24th 2024: [Produce a List of All Members Who Have Recommended Another Member from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day299.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: This problem involved using an INNER JOIN on the members table to find members who have recommended another member. I used the DISTINCT keyword to ensure each recommender appeared only once and sorted the results by surname and first name
25. Day 300 – September 25th 2024: [Produce a List of All Members, Along with Their Recommender from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day300.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: This problem required listing all members along with their recommender, so I performed self join with the members table on the recommendedby field being equal to the memid field. I used a LEFT JOIN to account for members without a recommender and ordered the results by the member’s surname and first name
26. Day 301 – September 26th 2024: [Produce a List of All Members Who Have Used a Tennis Court from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day301.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: This problem involved using multiple INNER JOINs to find members who have used a tennis court. I joined the members, bookings, and facilities tables, and used the IN keyword in combination with the WHERE keyword to filter for tennis courts. I used the || operator to concatenate the first and last names of members into a full name field, then used the DISTINCT() keyword to ensure each member only appears once per court they used
27. Day 302 – September 27th 2024: [Format the Names of Members from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day302.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: This problem required formatting the names of members by concatenating the surname and first name fields using the || operator, presenting names in the format "Surname, Firstname"
28. Day 303 – September 28th 2024: [Find Facilities by a Name Prefix from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day303.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: This problem involved finding facilities with names starting with "Tennis." I used the ILIKE operator to perform a search for names matching the 'Tennis%' prefix
29. Day 304 – September 29th 2024: [Perform a Case-Insensitive Search from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day304.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: This problem involved finding facilities with names starting with "Tennis" again, but with a case-insensitive search this time. Though the ILIKE operator automatically performs case insensitive searches, I also used the UPPER() function to demonstrate an alternate way that a case insensitive search can be done
30. Day 305 – September 30th 2024: [Find Telephone Numbers With Parentheses from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/september2024/day305.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: This problem involved finding telephone numbers that had parentheses around the first three numbers. I used the ILIKE operator here to search for records that started with a parenthesis

</details>



### October 2024

<details>

<summary>October 2024 Practice Problems</summary>

<br>

1. Day 306 – October 1st 2024: [Pad Zip Codes With Leading Zeroes from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day306.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: For this question, I needed to make zip codes of varying lengths a uniform 5 characters by padding any codes shorter than 5 characters with leading zeros. I used the PostgreSQL LPAD() function to complete this along with the CAST() function to change the integer zip codes into a character field
2. Day 307 – October 2nd 2024: [Count the Number of Members Whose Surname Starts With Each Letter of the Alphabet from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day307.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: For this question, I needed to count the number of members by the first letter of their surname. I used the COUNT() function to count the number of members, then I used the LEFT() function to extract the first letter of each surname. I did a GROUP BY each letter, then used the HAVING keyword to exclude letters without any members. Finally, I used the ORDER BY keyword to sort the output by letter alphabetically
3. Day 308 – October 3rd 2024: [Clean Up Telephone Numbers from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day308.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: This problem required removing special characters from the telephone numbers of each member. I used the REGEXP_REPLACE() function to replace characters like hyphens, parentheses, and spaces with an empty string, effectively cleaning the phone numbers. The output was ordered by member id
4. Day 309 – October 4th 2024: [Produce a Timestamp for 1 A.M. on the 31st of August 2012 from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day309.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: This problem required generating a specific timestamp. I used the TIMESTAMP literal to produce a timestamp for 1 a.m. on August 31st, 2012, directly specifying the date and time
5. Day 310 – October 5th 2024: [Subtract Timestamps from Each Other from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day310.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: This problem required calculating the difference between two timestamps. I used the subtraction operator (-) between two TIMESTAMP literals to determine the interval between them 
6. Day 311 – October 6th 2024: [Generate a List of All the Dates in October 2012 from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day311.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I used the GENERATE_SERIES() function to produce a list of all dates between October 1st and October 31st, 2012, with a step interval of one day
7. Day 312 – October 7th 2024: [Get the Day of the Month from a Timestamp from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day312.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: This problem required extracting the day of the month from a timestamp. I used the DATE_PART() function with the 'day' parameter to retrieve the day value
8. Day 313 – October 8th 2024: [Work Out the Number of Seconds Between Timestamps from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day313.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I used the EXTRACT(EPOCH) function to calculate the difference in seconds between two timestamps and rounded the result using ROUND()
9. Day 314 – October 9th 2024: [Work Out the Number of Days in Each Month of 2012 from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day314.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I generated a series of months using GENERATE_SERIES() and calculated the number of days in each month by subtracting the start of the month from the start of the next month
10. Day 315 – October 10th 2024: [Work Out the Number of Days Remaining in the Month from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day315.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I calculated the remaining days in the month by subtracting the current day’s timestamp from the last day of the month, determined using DATE_TRUNC() and intervals
11. Day 316 – October 11th 2024: [Work Out the End Time of Bookings from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day316.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I calculated booking end times by adding intervals based on the number of slots to the start times. I used INTERVAL arithmetic and ordered the results by endtime and starttime
12. Day 317 – October 12th 2024: [Return a Count of Bookings for Each Month from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day317.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I grouped bookings by month using DATE_TRUNC() and counted rows with COUNT() to get the total bookings per month, ordering results chronologically
13. Day 318 – October 13th 2024: [Work Out the Utilisation Percentage for Each Facility by Month from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day318.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: I used a WITH clause to calculate total slots per facility per month and computed utilisation as a percentage by dividing slots by available hours, rounding with ROUND()
14. Day 319 – October 14th 2024: [Produce a List of Costly Bookings from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day319.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I identified bookings over a specific cost using a CASE statement for cost calculation, JOINs to merge tables, and filtered results with WHERE. Results were sorted by cost in descending order
15. Day 320 – October 15th 2024: [Produce a List of All Members, Along with Their Recommender, Using No Joins from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day320.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I used a subquery to retrieve each member’s recommender without performing a join. The query included DISTINCT to avoid duplicates and ordered results by member names
16. Day 321 – October 16th 2024: [Produce a List of Costly Bookings, Using a Subquery from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day321.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I used a WITH clause to create a subquery calculating booking costs, then filtered the results for specific dates and costs greater than 30. The query included INNER JOINs for member and facility data
17. Day 322 – October 17th 2024: [Insert Some Data into a Table from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day322.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: I performed an INSERT INTO operation to add a new row to the facilities table, specifying all required column values
18. Day 323 – October 18th 2024: [Insert Multiple Rows of Data into a Table from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day323.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: I used the INSERT INTO statement to add multiple rows to the facilities table, specifying values for all required columns
19. Day 324 – October 19th 2024: [Insert Calculated Data into a Table from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day324.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I used a subquery in an INSERT INTO statement to calculate the next facility ID dynamically, ensuring no duplication in the facilities table
20. Day 325 – October 20th 2024: [Update Some Existing Data from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day325.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: I performed an UPDATE operation to modify a single row in the facilities table, setting the initialoutlay value for a specific facility
21. Day 326 – October 21st 2024: [Update Multiple Rows and Columns at the Same Time from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day326.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I updated multiple rows in the facilities table, modifying membercost and guestcost for specific facilities using the IN keyword
22. Day 327 – October 22nd 2024: [Update a Row Based on the Contents of Another Row from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day327.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I used a correlated subquery within an UPDATE statement to modify the membercost and guestcost of one row based on the values in another
23. Day 328 – October 23rd 2024: [Delete All Bookings from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day328.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: I used the DELETE statement to remove all rows from the bookings table
24. Day 329 – October 24th 2024: [Delete a Member from the cd.members Table from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day329.md)
    - Languages Used: SQL
    - Question Difficulty: Easy
    - Concepts Covered: I deleted a specific member from the members table using a WHERE clause to match the memid
25. Day 330 – October 25th 2024: [Delete Based on a Subquery from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day330.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I deleted rows from the members table where memid did not exist in the bookings table, using a subquery in the WHERE clause
26. Day 331 – October 26th 2024: [List the Total Slots Booked per Facility per Month, Part 2 from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day331.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I used the ROLLUP operator in a GROUP BY clause to calculate total slots booked per facility and month, including subtotals and grand totals
27. Day 332 – October 27th 2024: [List the Total Hours Booked per Named Facility from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day332.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I joined the bookings and facilities tables to calculate the total hours booked per facility, formatting the output with TO_CHAR() and ordering results by facility ID
28. Day 333 – October 28th 2024: [List Each Member's First Booking After September 1st 2012 from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day333.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I used MIN() to find each member's earliest booking after a specific date, grouping by member details and sorting by memid
29. Day 334 – October 29th 2024: [Produce a List of Member Names, with Each Row Containing the Total Member Count from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day334.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I used a subquery to calculate the total member count, including it in every row alongside member names, and sorted results by join date
30. Day 335 – October 30th 2024: [Produce a Numbered List of Members from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day335.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I used the ROW_NUMBER() window function to create a numbered list of members, ordering results by join date
31. Day 336 – October 31st 2024: [Output the Facility ID That Has the Highest Number of Slots Booked, Again from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/october2024/day336.md)
    - Languages Used: SQL
    - Question Difficulty: Medium
    - Concepts Covered: I used RANK() to rank facilities by total slots booked and filtered for the top-ranked facility using a WHERE clause

</details>


### November 2024

<details>

<summary>November 2024 Practice Problems</summary>

<br>

1. Day 337 – November 1st 2024: [Rank Members by (Rounded) Hours Used from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/november2024/day337.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: I calculated hours used by members with arithmetic expressions, ranked them using RANK(), and sorted by rank, surname, and first name
2. Day 338 – November 2nd 2024: [Find the Top Three Revenue Generating Facilities from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/november2024/day338.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: I used RANK() within a subquery to rank facilities based on their total revenue, calculated with a CASE statement. I filtered for the top three ranked facilities and ordered results by rank
3. Day 339 – November 3rd 2024: [Classify Facilities by Value from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/november2024/day339.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: I used NTILE() within a subquery to divide facilities into three groups based on revenue, then used a CASE statement to assign classifications of 'high', 'average', or 'low'. Results were ordered by classification and name
4. Day 340 – November 4th 2024: [Calculate the Payback Time for Each Facility from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/november2024/day340.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: I calculated payback time for each facility by dividing the initial outlay by the adjusted net revenue per month, using a CASE statement for revenue and grouping by facility ID.
5. Day 341 – November 5th 2024: [Calculate a Rolling Average of Total Revenue from PostgreSQL Exercises](https://github.com/LexiPugh/practice-problems/blob/main/practice_problems/november2024/day341.md)
    - Languages Used: SQL
    - Question Difficulty: Hard
    - Concepts Covered: I used a GENERATE_SERIES() to create daily dates, and a correlated subquery to calculate a rolling 15-day revenue average for each date. The subquery included CASE statements for revenue calculation and interval-based filtering.

</details>
